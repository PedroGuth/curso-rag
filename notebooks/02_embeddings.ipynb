{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# ğŸ§  **MÃ³dulo 2: Fundamentos de Embeddings - A Linguagem dos Computadores**\n",
       "\n",
       "> *Como transformar palavras em \"coordenadas\" que o computador entende*\n",
       "\n",
       "---\n",
       "\n",
       "## **Aula 2.1: Embeddings BÃ¡sicos - Como Transformar Texto em NÃºmeros**\n",
       "\n",
       "---\n",
       "\n",
       "### **TÃ¡, mas o que sÃ£o embeddings?**\n",
       "\n",
       "Embeddings sÃ£o como **tradutores universais** que transformam palavras em nÃºmeros que o computador entende. Ã‰ tipo transformar \"gato\" em coordenadas como (0.2, -0.8, 0.5, ...).\n",
       "\n",
       "**ğŸ–¼ï¸ SugestÃ£o de imagem**: Palavras sendo transformadas em coordenadas no espaÃ§o\n",
       "\n",
       "**Por que embeddings sÃ£o importantes?**\n",
       "\n",
       "Imagine que vocÃª quer encontrar roupas similares em uma loja:\n",
       "- ğŸ‘• **Sem embeddings**: \"Procure por camisetas azuis\" (muito especÃ­fico)\n",
       "- ğŸ§  **Com embeddings**: \"Encontre roupas com estilo similar\" (inteligente)\n",
       "\n",
       "### **Analogia do Dia a Dia**\n",
       "\n",
       "Embeddings sÃ£o como um **sistema de coordenadas geogrÃ¡ficas**:\n",
       "- ğŸŒ **SÃ£o Paulo**: (-23.5505, -46.6333)\n",
       "- ğŸŒ **Rio de Janeiro**: (-22.9068, -43.1729)\n",
       "- ğŸ§  **Gato**: (0.2, -0.8, 0.5, ...)\n",
       "- ğŸ§  **Cachorro**: (0.3, -0.7, 0.4, ...)\n",
       "\n",
       "**Palavras similares ficam prÃ³ximas no espaÃ§o!**\n",
       "\n",
       "---\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "Vamos importar as bibliotecas necessÃ¡rias:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ§  IMPORTAÃ‡Ã•ES PARA EMBEDDINGS\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "from sklearn.manifold import TSNE\n",
       "from sklearn.metrics.pairwise import cosine_similarity\n",
       "\n",
       "# LangChain\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_community.embeddings import OpenAIEmbeddings\n",
       "\n",
       "# UtilitÃ¡rios\n",
       "import os\n",
       "from dotenv import load_dotenv\n",
       "\n",
       "print(\"âœ… Bibliotecas importadas com sucesso!\")\n",
       "print(\"ğŸš€ Pronto para explorar o mundo dos embeddings!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo PrÃ¡tico - Embeddings Simples**\n",
       "\n",
       "Vamos comeÃ§ar com um exemplo simples para entender o conceito:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ§ª EXEMPLO PRÃTICO: EMBEDDINGS SIMPLES\n",
       "\n",
       "# Simulando embeddings simples (para demonstraÃ§Ã£o)\n",
       "def criar_embeddings_simples(palavras):\n",
       "    \"\"\"Cria embeddings simples para demonstraÃ§Ã£o\"\"\"\n",
       "    \n",
       "    # DicionÃ¡rio de embeddings simulados\n",
       "    embeddings_simples = {\n",
       "        \"gato\": [0.8, 0.2, 0.1],\n",
       "        \"cachorro\": [0.7, 0.3, 0.1],\n",
       "        \"peixe\": [0.1, 0.9, 0.2],\n",
       "        \"pÃ¡ssaro\": [0.2, 0.8, 0.3],\n",
       "        \"carro\": [0.9, 0.1, 0.8],\n",
       "        \"moto\": [0.8, 0.1, 0.9],\n",
       "        \"feliz\": [0.1, 0.1, 0.9],\n",
       "        \"triste\": [0.1, 0.1, 0.1],\n",
       "        \"grande\": [0.5, 0.5, 0.5],\n",
       "        \"pequeno\": [0.2, 0.2, 0.2]\n",
       "    }\n",
       "    \n",
       "    return {palavra: embeddings_simples.get(palavra, [0, 0, 0]) for palavra in palavras}\n",
       "\n",
       "# Testando embeddings simples\n",
       "palavras_teste = [\"gato\", \"cachorro\", \"peixe\", \"carro\", \"feliz\"]\n",
       "embeddings_simples = criar_embeddings_simples(palavras_teste)\n",
       "\n",
       "print(\"ğŸ§ª EMBEDDINGS SIMPLES (demonstraÃ§Ã£o):\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for palavra, embedding in embeddings_simples.items():\n",
       "    print(f\"ğŸ“ '{palavra}' â†’ {embedding}\")\n",
       "\n",
       "print(f\"\\nğŸ“Š DimensÃ£o dos embeddings: {len(embeddings_simples['gato'])}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Calculando Similaridade**\n",
       "\n",
       "Agora vamos ver como calcular similaridade entre embeddings:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ“Š CALCULANDO SIMILARIDADE ENTRE EMBEDDINGS\n",
       "\n",
       "def calcular_similaridade(embedding1, embedding2):\n",
       "    \"\"\"Calcula similaridade cosseno entre dois embeddings\"\"\"\n",
       "    \n",
       "    # Convertendo para arrays numpy\n",
       "    vec1 = np.array(embedding1)\n",
       "    vec2 = np.array(embedding2)\n",
       "    \n",
       "    # Similaridade cosseno\n",
       "    dot_product = np.dot(vec1, vec2)\n",
       "    norm1 = np.linalg.norm(vec1)\n",
       "    norm2 = np.linalg.norm(vec2)\n",
       "    \n",
       "    if norm1 == 0 or norm2 == 0:\n",
       "        return 0\n",
       "    \n",
       "    return dot_product / (norm1 * norm2)\n",
       "\n",
       "# Testando similaridades\n",
       "print(\"ğŸ“Š SIMILARIDADE ENTRE PALAVRAS:\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "comparacoes = [\n",
       "    (\"gato\", \"cachorro\"),\n",
       "    (\"gato\", \"peixe\"),\n",
       "    (\"carro\", \"moto\"),\n",
       "    (\"feliz\", \"triste\"),\n",
       "    (\"gato\", \"carro\")\n",
       "]\n",
       "\n",
       "for palavra1, palavra2 in comparacoes:\n",
       "    sim = calcular_similaridade(\n",
       "        embeddings_simples[palavra1], \n",
       "        embeddings_simples[palavra2]\n",
       "    )\n",
       "    \n",
       "    print(f\"ğŸ” '{palavra1}' vs '{palavra2}': {sim:.3f}\")\n",
       "    \n",
       "    # InterpretaÃ§Ã£o\n",
       "    if sim > 0.8:\n",
       "        print(f\"   âœ… Muito similares!\")\n",
       "    elif sim > 0.5:\n",
       "        print(f\"   ğŸ¤ Similares\")\n",
       "    elif sim > 0.2:\n",
       "        print(f\"   ğŸ¤” Pouco similares\")\n",
       "    else:\n",
       "        print(f\"   âŒ Muito diferentes\")\n",
       "    print()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Visualizando Embeddings**\n",
       "\n",
       "Vamos criar uma visualizaÃ§Ã£o para entender melhor como os embeddings se relacionam:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ“ˆ VISUALIZANDO EMBEDDINGS\n",
       "\n",
       "def visualizar_embeddings(embeddings_dict):\n",
       "    \"\"\"Cria visualizaÃ§Ã£o 2D dos embeddings\"\"\"\n",
       "    \n",
       "    # Preparando dados\n",
       "    palavras = list(embeddings_dict.keys())\n",
       "    embeddings = list(embeddings_dict.values())\n",
       "    \n",
       "    # Reduzindo para 2D (se necessÃ¡rio)\n",
       "    if len(embeddings[0]) > 2:\n",
       "        tsne = TSNE(n_components=2, random_state=42)\n",
       "        embeddings_2d = tsne.fit_transform(embeddings)\n",
       "    else:\n",
       "        embeddings_2d = embeddings\n",
       "    \n",
       "    # Criando grÃ¡fico\n",
       "    plt.figure(figsize=(12, 8))\n",
       "    \n",
       "    # Plotando pontos\n",
       "    x_coords = [coord[0] for coord in embeddings_2d]\n",
       "    y_coords = [coord[1] for coord in embeddings_2d]\n",
       "    \n",
       "    plt.scatter(x_coords, y_coords, s=100, alpha=0.7)\n",
       "    \n",
       "    # Adicionando labels\n",
       "    for i, palavra in enumerate(palavras):\n",
       "        plt.annotate(palavra, (x_coords[i], y_coords[i]), \n",
       "                    xytext=(5, 5), textcoords='offset points',\n",
       "                    fontsize=12, fontweight='bold')\n",
       "    \n",
       "    plt.title('ğŸ§  VisualizaÃ§Ã£o dos Embeddings', fontsize=16, fontweight='bold')\n",
       "    plt.xlabel('DimensÃ£o 1')\n",
       "    plt.ylabel('DimensÃ£o 2')\n",
       "    plt.grid(True, alpha=0.3)\n",
       "    \n",
       "    # Adicionando legenda\n",
       "    plt.figtext(0.02, 0.02, \n",
       "                'ğŸ’¡ Palavras similares ficam prÃ³ximas no espaÃ§o!', \n",
       "                fontsize=10, style='italic')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "\n",
       "# Visualizando nossos embeddings simples\n",
       "print(\"ğŸ“ˆ Criando visualizaÃ§Ã£o dos embeddings...\")\n",
       "visualizar_embeddings(embeddings_simples)\n",
       "\n",
       "print(\"âœ… VisualizaÃ§Ã£o criada! Observe como palavras similares ficam prÃ³ximas!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 2.2: Embeddings AvanÃ§ados - Otimizando a Qualidade**\n",
       "\n",
       "---\n",
       "\n",
       "### **TÃ¡, mas como funcionam embeddings reais?**\n",
       "\n",
       "Embeddings reais sÃ£o criados por **redes neurais** que aprendem a representar palavras baseado no contexto. Ã‰ como um tradutor que entende nuances e significados.\n",
       "\n",
       "**ğŸ–¼ï¸ SugestÃ£o de imagem**: Rede neural processando texto\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "Vamos configurar embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ”§ CONFIGURANDO EMBEDDINGS REAIS\n",
       "\n",
       "def configurar_embeddings():\n",
       "    \"\"\"Configura modelo de embeddings real\"\"\"\n",
       "    \n",
       "    try:\n",
       "        print(\"ğŸš€ Carregando Sentence Transformers...\")\n",
       "        \n",
       "        # Modelo pequeno e rÃ¡pido para demonstraÃ§Ã£o\n",
       "        embeddings = HuggingFaceEmbeddings(\n",
       "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
       "            model_kwargs={'device': 'cpu'}\n",
       "        )\n",
       "        \n",
       "        print(\"âœ… Embeddings configurados com sucesso!\")\n",
       "        return embeddings\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"âš ï¸ Erro ao carregar embeddings: {e}\")\n",
       "        print(\"ğŸ’¡ Vamos usar embeddings simulados para continuar\")\n",
       "        return None\n",
       "\n",
       "# Configurando embeddings\n",
       "embeddings_real = configurar_embeddings()\n",
       "\n",
       "if embeddings_real:\n",
       "    print(f\"ğŸ“Š DimensÃ£o dos embeddings: {embeddings_real.client.get_sentence_embedding_dimension()}\")\n",
       "else:\n",
       "    print(\"âš ï¸ Usando embeddings simulados para demonstraÃ§Ã£o\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo PrÃ¡tico - Embeddings Reais**\n",
       "\n",
       "Agora vamos testar embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ§ª EXEMPLO PRÃTICO: EMBEDDINGS REAIS\n",
       "\n",
       "def testar_embeddings_reais():\n",
       "    \"\"\"Testa embeddings reais com frases\"\"\"\n",
       "    \n",
       "    # Frases para teste\n",
       "    frases_teste = [\n",
       "        \"O gato estÃ¡ dormindo no sofÃ¡\",\n",
       "        \"O cachorro estÃ¡ brincando no jardim\",\n",
       "        \"O peixe estÃ¡ nadando no aquÃ¡rio\",\n",
       "        \"O carro estÃ¡ estacionado na garagem\",\n",
       "        \"A pessoa estÃ¡ feliz com a notÃ­cia\",\n",
       "        \"A pessoa estÃ¡ triste com a perda\"\n",
       "    ]\n",
       "    \n",
       "    if embeddings_real:\n",
       "        print(\"ğŸ§ª TESTANDO EMBEDDINGS REAIS:\")\n",
       "        print(\"=\" * 50)\n",
       "        \n",
       "        # Gerando embeddings\n",
       "        embeddings_gerados = embeddings_real.embed_documents(frases_teste)\n",
       "        \n",
       "        print(f\"âœ… Gerados {len(embeddings_gerados)} embeddings\")\n",
       "        print(f\"ğŸ“Š DimensÃ£o de cada embedding: {len(embeddings_gerados[0])}\")\n",
       "        \n",
       "        # Calculando similaridades\n",
       "        print(\"\\nğŸ“Š SIMILARIDADES ENTRE FRASES:\")\n",
       "        \n",
       "        comparacoes_frases = [\n",
       "            (0, 1, \"Gato vs Cachorro\"),\n",
       "            (0, 2, \"Gato vs Peixe\"),\n",
       "            (3, 3, \"Carro vs Carro (mesmo)\"),\n",
       "            (4, 5, \"Feliz vs Triste\")\n",
       "        ]\n",
       "        \n",
       "        for i, j, descricao in comparacoes_frases:\n",
       "            sim = cosine_similarity(\n",
       "                [embeddings_gerados[i]], \n",
       "                [embeddings_gerados[j]]\n",
       "            )[0][0]\n",
       "            \n",
       "            print(f\"ğŸ” {descricao}: {sim:.3f}\")\n",
       "            \n",
       "            if sim > 0.8:\n",
       "                print(f\"   âœ… Muito similares!\")\n",
       "            elif sim > 0.5:\n",
       "                print(f\"   ğŸ¤ Similares\")\n",
       "            elif sim > 0.2:\n",
       "                print(f\"   ğŸ¤” Pouco similares\")\n",
       "            else:\n",
       "                print(f\"   âŒ Muito diferentes\")\n",
       "            print()\n",
       "        \n",
       "        return embeddings_gerados, frases_teste\n",
       "        \n",
       "    else:\n",
       "        print(\"âš ï¸ Embeddings reais nÃ£o disponÃ­veis\")\n",
       "        return None, None\n",
       "\n",
       "# Testando embeddings reais\n",
       "embeddings_reais, frases = testar_embeddings_reais()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Visualizando Embeddings Reais**\n",
       "\n",
       "Vamos criar uma visualizaÃ§Ã£o dos embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ“ˆ VISUALIZANDO EMBEDDINGS REAIS\n",
       "\n",
       "if embeddings_reais is not None:\n",
       "    print(\"ğŸ“ˆ Criando visualizaÃ§Ã£o dos embeddings reais...\")\n",
       "    \n",
       "    # Reduzindo para 2D\n",
       "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(embeddings_reais)-1))\n",
       "    embeddings_2d = tsne.fit_transform(embeddings_reais)\n",
       "    \n",
       "    # Criando grÃ¡fico\n",
       "    plt.figure(figsize=(14, 10))\n",
       "    \n",
       "    # Plotando pontos\n",
       "    x_coords = embeddings_2d[:, 0]\n",
       "    y_coords = embeddings_2d[:, 1]\n",
       "    \n",
       "    plt.scatter(x_coords, y_coords, s=150, alpha=0.7, c='skyblue', edgecolors='navy')\n",
       "    \n",
       "    # Adicionando labels\n",
       "    for i, frase in enumerate(frases):\n",
       "        # Abreviando frase para melhor visualizaÃ§Ã£o\n",
       "        label = frase[:20] + \"...\" if len(frase) > 20 else frase\n",
       "        plt.annotate(label, (x_coords[i], y_coords[i]), \n",
       "                    xytext=(5, 5), textcoords='offset points',\n",
       "                    fontsize=10, fontweight='bold',\n",
       "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
       "    \n",
       "    plt.title('ğŸ§  VisualizaÃ§Ã£o dos Embeddings Reais', fontsize=16, fontweight='bold')\n",
       "    plt.xlabel('DimensÃ£o 1 (TSNE)')\n",
       "    plt.ylabel('DimensÃ£o 2 (TSNE)')\n",
       "    plt.grid(True, alpha=0.3)\n",
       "    \n",
       "    # Adicionando legenda\n",
       "    plt.figtext(0.02, 0.02, \n",
       "                'ğŸ’¡ Frases com significado similar ficam prÃ³ximas!', \n",
       "                fontsize=10, style='italic')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "    print(\"âœ… VisualizaÃ§Ã£o criada! Observe como frases similares se agrupam!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Teste RÃ¡pido**\n",
       "\n",
       "Vamos fazer um teste rÃ¡pido para encontrar frases similares:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ§ª TESTE RÃPIDO: ENCONTRANDO FRASES SIMILARES\n",
       "\n",
       "def encontrar_frases_similares(frase_consulta, frases, embeddings, top_k=3):\n",
       "    \"\"\"Encontra as frases mais similares a uma consulta\"\"\"\n",
       "    \n",
       "    if embeddings_real:\n",
       "        # Gerando embedding da consulta\n",
       "        embedding_consulta = embeddings_real.embed_query(frase_consulta)\n",
       "        \n",
       "        # Calculando similaridades\n",
       "        similaridades = []\n",
       "        for i, embedding in enumerate(embeddings):\n",
       "            sim = cosine_similarity([embedding_consulta], [embedding])[0][0]\n",
       "            similaridades.append((i, sim))\n",
       "        \n",
       "        # Ordenando por similaridade\n",
       "        similaridades.sort(key=lambda x: x[1], reverse=True)\n",
       "        \n",
       "        print(f\"ğŸ” Consulta: '{frase_consulta}'\")\n",
       "        print(f\"ğŸ“Š Top {top_k} frases mais similares:\")\n",
       "        print(\"=\" * 50)\n",
       "        \n",
       "        for rank, (idx, sim) in enumerate(similaridades[:top_k], 1):\n",
       "            print(f\"{rank}. {frases[idx]}\")\n",
       "            print(f\"   Similaridade: {sim:.3f}\")\n",
       "            print()\n",
       "        \n",
       "    else:\n",
       "        print(\"âš ï¸ Embeddings reais nÃ£o disponÃ­veis para este teste\")\n",
       "\n",
       "# Testando busca por similaridade\n",
       "if embeddings_reais is not None:\n",
       "    print(\"ğŸ§ª TESTE DE BUSCA POR SIMILARIDADE:\")\n",
       "    print(\"=\" * 50)\n",
       "    \n",
       "    consultas_teste = [\n",
       "        \"Um animal domÃ©stico\",\n",
       "        \"Um veÃ­culo motorizado\",\n",
       "        \"Uma emoÃ§Ã£o positiva\"\n",
       "    ]\n",
       "    \n",
       "    for consulta in consultas_teste:\n",
       "        encontrar_frases_similares(consulta, frases, embeddings_reais)\n",
       "        print(\"-\" * 30)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Desafio do MÃ³dulo**\n",
       "\n",
       "Agora Ã© sua vez! Crie seus prÃ³prios embeddings:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ğŸ¯ DESAFIO DO MÃ“DULO\n",
       "\n",
       "print(\"ğŸ¯ DESAFIO: Crie seus prÃ³prios embeddings!\")\n",
       "print(\"=\" * 40)\n",
       "print(\"1. Adicione suas prÃ³prias frases na lista abaixo\")\n",
       "print(\"2. Execute o cÃ³digo para gerar embeddings\")\n",
       "print(\"3. Teste similaridades entre suas frases\")\n",
       "print(\"=\" * 40)\n",
       "\n",
       "# Suas frases personalizadas\n",
       "minhas_frases = [\n",
       "    # Adicione aqui frases sobre um tema que vocÃª gosta\n",
       "    # Exemplo: filmes, mÃºsica, esportes, tecnologia, etc.\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\"\n",
       "]\n",
       "\n",
       "# Descomente e execute quando tiver suas frases:\n",
       "# if embeddings_real and any(minhas_frases):\n",
       "#     print(\"\\nğŸ§ª GERANDO EMBEDDINGS PARA SUAS FRASES:\")\n",
       "#     meus_embeddings = embeddings_real.embed_documents(minhas_frases)\n",
       "#     print(f\"âœ… Gerados {len(meus_embeddings)} embeddings\")\n",
       "#     \n",
       "#     # Teste de similaridade\n",
       "#     consulta_pessoal = \"Sua consulta aqui\"\n",
       "#     encontrar_frases_similares(consulta_pessoal, minhas_frases, meus_embeddings)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **ğŸ‰ MÃ³dulo 2 ConcluÃ­do!**\n",
       "\n",
       "### **âœ… O que aprendemos:**\n",
       "\n",
       "1. **ğŸ§  O que sÃ£o embeddings**: TransformaÃ§Ã£o de texto em nÃºmeros\n",
       "2. **ğŸ“Š Similaridade**: Como calcular proximidade entre textos\n",
       "3. **ğŸ“ˆ VisualizaÃ§Ã£o**: Como entender relaÃ§Ãµes entre embeddings\n",
       "4. **ğŸš€ Embeddings reais**: Usando modelos profissionais\n",
       "5. **ğŸ” Busca por similaridade**: Encontrando textos relacionados\n",
       "\n",
       "### **ğŸš€ PrÃ³ximos Passos:**\n",
       "\n",
       "No prÃ³ximo mÃ³dulo vamos aprender sobre **Vector Stores** - onde guardar todos esses embeddings de forma eficiente!\n",
       "\n",
       "### **ğŸ’¡ Dicas Importantes:**\n",
       "\n",
       "- **Embeddings capturam significado** - nÃ£o apenas palavras\n",
       "- **Similaridade cosseno** Ã© a mÃ©trica mais usada\n",
       "- **DimensÃµes maiores** = mais precisÃ£o (mas mais lento)\n",
       "- **Modelos prÃ©-treinados** sÃ£o melhores que treinar do zero\n",
       "\n",
       "---\n",
       "\n",
       "**ğŸ¯ Desafio do MÃ³dulo**: Crie embeddings para suas prÃ³prias frases!\n",
       "\n",
       "**ğŸ’¡ Dica do Pedro**: Embeddings sÃ£o como GPS para palavras - cada palavra tem suas coordenadas no espaÃ§o!\n",
       "\n",
       "**ğŸš€ PrÃ³ximo mÃ³dulo**: Vector Stores - A memÃ³ria inteligente!"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }