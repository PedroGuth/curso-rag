{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# üß† **M√≥dulo 2: Fundamentos de Embeddings - A Linguagem dos Computadores**\n",
       "\n",
       "> *Como transformar palavras em \"coordenadas\" que o computador entende*\n",
       "\n",
       "---\n",
       "\n",
       "## **Aula 2.1: Embeddings B√°sicos - Como Transformar Texto em N√∫meros**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas o que s√£o embeddings?**\n",
       "\n",
       "Embeddings s√£o como **tradutores universais** que transformam palavras em n√∫meros que o computador entende. √â tipo transformar \"gato\" em coordenadas como (0.2, -0.8, 0.5, ...).\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Palavras sendo transformadas em coordenadas no espa√ßo\n",
       "\n",
       "**Por que embeddings s√£o importantes?**\n",
       "\n",
       "Imagine que voc√™ quer encontrar roupas similares em uma loja:\n",
       "- üëï **Sem embeddings**: \"Procure por camisetas azuis\" (muito espec√≠fico)\n",
       "- üß† **Com embeddings**: \"Encontre roupas com estilo similar\" (inteligente)\n",
       "\n",
       "### **Analogia do Dia a Dia**\n",
       "\n",
       "Embeddings s√£o como um **sistema de coordenadas geogr√°ficas**:\n",
       "- üåç **S√£o Paulo**: (-23.5505, -46.6333)\n",
       "- üåç **Rio de Janeiro**: (-22.9068, -43.1729)\n",
       "- ÔøΩÔøΩ **Gato**: (0.2, -0.8, 0.5, ...)\n",
       "- ÔøΩÔøΩ **Cachorro**: (0.3, -0.7, 0.4, ...)\n",
       "\n",
       "**Palavras similares ficam pr√≥ximas no espa√ßo!**\n",
       "\n",
       "---\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "**‚ö†Ô∏è IMPORTANTE**: Se voc√™ n√£o executou o notebook `00_setup_colab.ipynb` primeiro, execute a c√©lula abaixo para instalar as depend√™ncias."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üöÄ SETUP GRATUITO PARA COLAB\n",
       "# Execute esta c√©lula primeiro para configurar o ambiente!\n",
       "\n",
       "# Instalando depend√™ncias (execute apenas se necess√°rio)\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install huggingface_hub>=0.19.0\n",
       "!pip install sentence-transformers>=2.2.0\n",
       "!pip install chromadb>=0.4.0\n",
       "!pip install faiss-cpu>=1.7.0\n",
       "!pip install numpy>=1.24.0\n",
       "!pip install pandas>=2.0.0\n",
       "!pip install matplotlib>=3.5.0\n",
       "!pip install scikit-learn>=1.3.0\n",
       "\n",
       "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")\n",
       "print(\"üöÄ Ambiente configurado para Embeddings!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß† IMPORTA√á√ïES PARA EMBEDDINGS\n",
       "import numpy as np\n",
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "from sklearn.manifold import TSNE\n",
       "from sklearn.metrics.pairwise import cosine_similarity\n",
       "\n",
       "# LangChain\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_community.embeddings import OpenAIEmbeddings\n",
       "\n",
       "# Utilit√°rios\n",
       "import os\n",
       "from dotenv import load_dotenv\n",
       "\n",
       "print(\"‚úÖ Bibliotecas importadas com sucesso!\")\n",
       "print(\"ÔøΩÔøΩ Pronto para explorar o mundo dos embeddings!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo Pr√°tico - Embeddings Simples**\n",
       "\n",
       "Vamos come√ßar com um exemplo simples para entender o conceito:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ EXEMPLO PR√ÅTICO: EMBEDDINGS SIMPLES\n",
       "\n",
       "# Simulando embeddings simples (para demonstra√ß√£o)\n",
       "def criar_embeddings_simples(palavras):\n",
       "    \"\"\"Cria embeddings simples para demonstra√ß√£o\"\"\"\n",
       "    \n",
       "    # Dicion√°rio de embeddings simulados\n",
       "    embeddings_simples = {\n",
       "        \"gato\": [0.8, 0.2, 0.1],\n",
       "        \"cachorro\": [0.7, 0.3, 0.1],\n",
       "        \"peixe\": [0.1, 0.9, 0.2],\n",
       "        \"p√°ssaro\": [0.2, 0.8, 0.3],\n",
       "        \"carro\": [0.9, 0.1, 0.8],\n",
       "        \"moto\": [0.8, 0.1, 0.9],\n",
       "        \"feliz\": [0.1, 0.1, 0.9],\n",
       "        \"triste\": [0.1, 0.1, 0.1],\n",
       "        \"grande\": [0.5, 0.5, 0.5],\n",
       "        \"pequeno\": [0.2, 0.2, 0.2]\n",
       "    }\n",
       "    \n",
       "    return {palavra: embeddings_simples.get(palavra, [0, 0, 0]) for palavra in palavras}\n",
       "\n",
       "# Testando embeddings simples\n",
       "palavras_teste = [\"gato\", \"cachorro\", \"peixe\", \"carro\", \"feliz\"]\n",
       "embeddings_simples = criar_embeddings_simples(palavras_teste)\n",
       "\n",
       "print(\"ÔøΩÔøΩ EMBEDDINGS SIMPLES (demonstra√ß√£o):\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for palavra, embedding in embeddings_simples.items():\n",
       "    print(f\"üìù '{palavra}' ‚Üí {embedding}\")\n",
       "\n",
       "print(f\"\\nüìä Dimens√£o dos embeddings: {len(embeddings_simples['gato'])}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Calculando Similaridade**\n",
       "\n",
       "Agora vamos ver como calcular similaridade entre embeddings:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CALCULANDO SIMILARIDADE ENTRE EMBEDDINGS\n",
       "\n",
       "def calcular_similaridade(embedding1, embedding2):\n",
       "    \"\"\"Calcula similaridade cosseno entre dois embeddings\"\"\"\n",
       "    \n",
       "    # Convertendo para arrays numpy\n",
       "    vec1 = np.array(embedding1)\n",
       "    vec2 = np.array(embedding2)\n",
       "    \n",
       "    # Similaridade cosseno\n",
       "    dot_product = np.dot(vec1, vec2)\n",
       "    norm1 = np.linalg.norm(vec1)\n",
       "    norm2 = np.linalg.norm(vec2)\n",
       "    \n",
       "    if norm1 == 0 or norm2 == 0:\n",
       "        return 0\n",
       "    \n",
       "    return dot_product / (norm1 * norm2)\n",
       "\n",
       "# Testando similaridades\n",
       "print(\"ÔøΩÔøΩ SIMILARIDADE ENTRE PALAVRAS:\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "comparacoes = [\n",
       "    (\"gato\", \"cachorro\"),\n",
       "    (\"gato\", \"peixe\"),\n",
       "    (\"carro\", \"moto\"),\n",
       "    (\"feliz\", \"triste\"),\n",
       "    (\"gato\", \"carro\")\n",
       "]\n",
       "\n",
       "for palavra1, palavra2 in comparacoes:\n",
       "    sim = calcular_similaridade(\n",
       "        embeddings_simples[palavra1], \n",
       "        embeddings_simples[palavra2]\n",
       "    )\n",
       "    \n",
       "    print(f\"ÔøΩÔøΩ '{palavra1}' vs '{palavra2}': {sim:.3f}\")\n",
       "    \n",
       "    # Interpreta√ß√£o\n",
       "    if sim > 0.8:\n",
       "        print(f\"   ‚úÖ Muito similares!\")\n",
       "    elif sim > 0.5:\n",
       "        print(f\"   ü§ù Similares\")\n",
       "    elif sim > 0.2:\n",
       "        print(f\"   ü§î Pouco similares\")\n",
       "    else:\n",
       "        print(f\"   ‚ùå Muito diferentes\")\n",
       "    print()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Visualizando Embeddings**\n",
       "\n",
       "Vamos criar uma visualiza√ß√£o para entender melhor como os embeddings se relacionam:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ VISUALIZANDO EMBEDDINGS\n",
       "\n",
       "def visualizar_embeddings(embeddings_dict):\n",
       "    \"\"\"Cria visualiza√ß√£o 2D dos embeddings\"\"\"\n",
       "    \n",
       "    # Preparando dados\n",
       "    palavras = list(embeddings_dict.keys())\n",
       "    embeddings = list(embeddings_dict.values())\n",
       "    \n",
       "    # Reduzindo para 2D (se necess√°rio)\n",
       "    if len(embeddings[0]) > 2:\n",
       "        tsne = TSNE(n_components=2, random_state=42)\n",
       "        embeddings_2d = tsne.fit_transform(embeddings)\n",
       "    else:\n",
       "        embeddings_2d = embeddings\n",
       "    \n",
       "    # Criando gr√°fico\n",
       "    plt.figure(figsize=(12, 8))\n",
       "    \n",
       "    # Plotando pontos\n",
       "    x_coords = [coord[0] for coord in embeddings_2d]\n",
       "    y_coords = [coord[1] for coord in embeddings_2d]\n",
       "    \n",
       "    plt.scatter(x_coords, y_coords, s=100, alpha=0.7)\n",
       "    \n",
       "    # Adicionando labels\n",
       "    for i, palavra in enumerate(palavras):\n",
       "        plt.annotate(palavra, (x_coords[i], y_coords[i]), \n",
       "                    xytext=(5, 5), textcoords='offset points',\n",
       "                    fontsize=12, fontweight='bold')\n",
       "    \n",
       "    plt.title('üß† Visualiza√ß√£o dos Embeddings', fontsize=16, fontweight='bold')\n",
       "    plt.xlabel('Dimens√£o 1')\n",
       "    plt.ylabel('Dimens√£o 2')\n",
       "    plt.grid(True, alpha=0.3)\n",
       "    \n",
       "    # Adicionando legenda\n",
       "    plt.figtext(0.02, 0.02, \n",
       "                'ÔøΩÔøΩ Palavras similares ficam pr√≥ximas no espa√ßo!', \n",
       "                fontsize=10, style='italic')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "\n",
       "# Visualizando nossos embeddings simples\n",
       "print(\"üìà Criando visualiza√ß√£o dos embeddings...\")\n",
       "visualizar_embeddings(embeddings_simples)\n",
       "\n",
       "print(\"‚úÖ Visualiza√ß√£o criada! Observe como palavras similares ficam pr√≥ximas!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 2.2: Embeddings Avan√ßados - Otimizando a Qualidade**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas como funcionam embeddings reais?**\n",
       "\n",
       "Embeddings reais s√£o criados por **redes neurais** que aprendem a representar palavras baseado no contexto. √â como um tradutor que entende nuances e significados.\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Rede neural processando texto\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "Vamos configurar embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CONFIGURANDO EMBEDDINGS REAIS\n",
       "\n",
       "def configurar_embeddings():\n",
       "    \"\"\"Configura modelo de embeddings real\"\"\"\n",
       "    \n",
       "    try:\n",
       "        print(\"üöÄ Carregando Sentence Transformers...\")\n",
       "        \n",
       "        # Modelo pequeno e r√°pido para demonstra√ß√£o\n",
       "        embeddings = HuggingFaceEmbeddings(\n",
       "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
       "            model_kwargs={'device': 'cpu'}\n",
       "        )\n",
       "        \n",
       "        print(\"‚úÖ Embeddings configurados com sucesso!\")\n",
       "        return embeddings\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ö†Ô∏è Erro ao carregar embeddings: {e}\")\n",
       "        print(\"üí° Vamos usar embeddings simulados para continuar\")\n",
       "        return None\n",
       "\n",
       "# Configurando embeddings\n",
       "embeddings_real = configurar_embeddings()\n",
       "\n",
       "if embeddings_real:\n",
       "    print(f\"üìä Dimens√£o dos embeddings: {embeddings_real.client.get_sentence_embedding_dimension()}\")\n",
       "else:\n",
       "    print(\"‚ö†Ô∏è Usando embeddings simulados para demonstra√ß√£o\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo Pr√°tico - Embeddings Reais**\n",
       "\n",
       "Agora vamos testar embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ EXEMPLO PR√ÅTICO: EMBEDDINGS REAIS\n",
       "\n",
       "def testar_embeddings_reais():\n",
       "    \"\"\"Testa embeddings reais com frases\"\"\"\n",
       "    \n",
       "    # Frases para teste\n",
       "    frases_teste = [\n",
       "        \"O gato est√° dormindo no sof√°\",\n",
       "        \"O cachorro est√° brincando no jardim\",\n",
       "        \"O peixe est√° nadando no aqu√°rio\",\n",
       "        \"O carro est√° estacionado na garagem\",\n",
       "        \"A pessoa est√° feliz com a not√≠cia\",\n",
       "        \"A pessoa est√° triste com a perda\"\n",
       "    ]\n",
       "    \n",
       "    if embeddings_real:\n",
       "        print(\"üß™ TESTANDO EMBEDDINGS REAIS:\")\n",
       "        print(\"=\" * 50)\n",
       "        \n",
       "        # Gerando embeddings\n",
       "        embeddings_gerados = embeddings_real.embed_documents(frases_teste)\n",
       "        \n",
       "        print(f\"‚úÖ Gerados {len(embeddings_gerados)} embeddings\")\n",
       "        print(f\"üìä Dimens√£o de cada embedding: {len(embeddings_gerados[0])}\")\n",
       "        \n",
       "        # Calculando similaridades\n",
       "        print(\"\\nüìä SIMILARIDADES ENTRE FRASES:\")\n",
       "        \n",
       "        comparacoes_frases = [\n",
       "            (0, 1, \"Gato vs Cachorro\"),\n",
       "            (0, 2, \"Gato vs Peixe\"),\n",
       "            (3, 3, \"Carro vs Carro (mesmo)\"),\n",
       "            (4, 5, \"Feliz vs Triste\")\n",
       "        ]\n",
       "        \n",
       "        for i, j, descricao in comparacoes_frases:\n",
       "            sim = cosine_similarity(\n",
       "                [embeddings_gerados[i]], \n",
       "                [embeddings_gerados[j]]\n",
       "            )[0][0]\n",
       "            \n",
       "            print(f\"üîç {descricao}: {sim:.3f}\")\n",
       "            \n",
       "            if sim > 0.8:\n",
       "                print(f\"   ‚úÖ Muito similares!\")\n",
       "            elif sim > 0.5:\n",
       "                print(f\"   ü§ù Similares\")\n",
       "            elif sim > 0.2:\n",
       "                print(f\"   ü§î Pouco similares\")\n",
       "            else:\n",
       "                print(f\"   ‚ùå Muito diferentes\")\n",
       "            print()\n",
       "        \n",
       "        return embeddings_gerados, frases_teste\n",
       "        \n",
       "    else:\n",
       "        print(\"‚ö†Ô∏è Embeddings reais n√£o dispon√≠veis\")\n",
       "        return None, None\n",
       "\n",
       "# Testando embeddings reais\n",
       "embeddings_reais, frases = testar_embeddings_reais()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Visualizando Embeddings Reais**\n",
       "\n",
       "Vamos criar uma visualiza√ß√£o dos embeddings reais:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ VISUALIZANDO EMBEDDINGS REAIS\n",
       "\n",
       "if embeddings_reais is not None:\n",
       "    print(\"üìà Criando visualiza√ß√£o dos embeddings reais...\")\n",
       "    \n",
       "    # Reduzindo para 2D\n",
       "    tsne = TSNE(n_components=2, random_state=42, perplexity=min(5, len(embeddings_reais)-1))\n",
       "    embeddings_2d = tsne.fit_transform(embeddings_reais)\n",
       "    \n",
       "    # Criando gr√°fico\n",
       "    plt.figure(figsize=(14, 10))\n",
       "    \n",
       "    # Plotando pontos\n",
       "    x_coords = embeddings_2d[:, 0]\n",
       "    y_coords = embeddings_2d[:, 1]\n",
       "    \n",
       "    plt.scatter(x_coords, y_coords, s=150, alpha=0.7, c='skyblue', edgecolors='navy')\n",
       "    \n",
       "    # Adicionando labels\n",
       "    for i, frase in enumerate(frases):\n",
       "        # Abreviando frase para melhor visualiza√ß√£o\n",
       "        label = frase[:20] + \"...\" if len(frase) > 20 else frase\n",
       "        plt.annotate(label, (x_coords[i], y_coords[i]), \n",
       "                    xytext=(5, 5), textcoords='offset points',\n",
       "                    fontsize=10, fontweight='bold',\n",
       "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"white\", alpha=0.8))\n",
       "    \n",
       "    plt.title('üß† Visualiza√ß√£o dos Embeddings Reais', fontsize=16, fontweight='bold')\n",
       "    plt.xlabel('Dimens√£o 1 (TSNE)')\n",
       "    plt.ylabel('Dimens√£o 2 (TSNE)')\n",
       "    plt.grid(True, alpha=0.3)\n",
       "    \n",
       "    # Adicionando legenda\n",
       "    plt.figtext(0.02, 0.02, \n",
       "                'üí° Frases com significado similar ficam pr√≥ximas!', \n",
       "                fontsize=10, style='italic')\n",
       "    \n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "    print(\"‚úÖ Visualiza√ß√£o criada! Observe como frases similares se agrupam!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Teste R√°pido**\n",
       "\n",
       "Vamos fazer um teste r√°pido para encontrar frases similares:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ TESTE R√ÅPIDO: ENCONTRANDO FRASES SIMILARES\n",
       "\n",
       "def encontrar_frases_similares(frase_consulta, frases, embeddings, top_k=3):\n",
       "    \"\"\"Encontra as frases mais similares a uma consulta\"\"\"\n",
       "    \n",
       "    if embeddings_real:\n",
       "        # Gerando embedding da consulta\n",
       "        embedding_consulta = embeddings_real.embed_query(frase_consulta)\n",
       "        \n",
       "        # Calculando similaridades\n",
       "        similaridades = []\n",
       "        for i, embedding in enumerate(embeddings):\n",
       "            sim = cosine_similarity([embedding_consulta], [embedding])[0][0]\n",
       "            similaridades.append((i, sim))\n",
       "        \n",
       "        # Ordenando por similaridade\n",
       "        similaridades.sort(key=lambda x: x[1], reverse=True)\n",
       "        \n",
       "        print(f\"ÔøΩÔøΩ Consulta: '{frase_consulta}'\")\n",
       "        print(f\"ÔøΩÔøΩ Top {top_k} frases mais similares:\")\n",
       "        print(\"=\" * 50)\n",
       "        \n",
       "        for rank, (idx, sim) in enumerate(similaridades[:top_k], 1):\n",
       "            print(f\"{rank}. {frases[idx]}\")\n",
       "            print(f\"   Similaridade: {sim:.3f}\")\n",
       "            print()\n",
       "        \n",
       "    else:\n",
       "        print(\"‚ö†Ô∏è Embeddings reais n√£o dispon√≠veis para este teste\")\n",
       "\n",
       "# Testando busca por similaridade\n",
       "if embeddings_reais is not None:\n",
       "    print(\"ÔøΩÔøΩ TESTE DE BUSCA POR SIMILARIDADE:\")\n",
       "    print(\"=\" * 50)\n",
       "    \n",
       "    consultas_teste = [\n",
       "        \"Um animal dom√©stico\",\n",
       "        \"Um ve√≠culo motorizado\",\n",
       "        \"Uma emo√ß√£o positiva\"\n",
       "    ]\n",
       "    \n",
       "    for consulta in consultas_teste:\n",
       "        encontrar_frases_similares(consulta, frases, embeddings_reais)\n",
       "        print(\"-\" * 30)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Desafio do M√≥dulo**\n",
       "\n",
       "Agora √© sua vez! Crie seus pr√≥prios embeddings:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üéØ DESAFIO DO M√ìDULO\n",
       "\n",
       "print(\"ÔøΩÔøΩ DESAFIO: Crie seus pr√≥prios embeddings!\")\n",
       "print(\"=\" * 40)\n",
       "print(\"1. Adicione suas pr√≥prias frases na lista abaixo\")\n",
       "print(\"2. Execute o c√≥digo para gerar embeddings\")\n",
       "print(\"3. Teste similaridades entre suas frases\")\n",
       "print(\"=\" * 40)\n",
       "\n",
       "# Suas frases personalizadas\n",
       "minhas_frases = [\n",
       "    # Adicione aqui frases sobre um tema que voc√™ gosta\n",
       "    # Exemplo: filmes, m√∫sica, esportes, tecnologia, etc.\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\",\n",
       "    \"\"\n",
       "]\n",
       "\n",
       "# Descomente e execute quando tiver suas frases:\n",
       "# if embeddings_real and any(minhas_frases):\n",
       "#     print(\"\\nÔøΩÔøΩ GERANDO EMBEDDINGS PARA SUAS FRASES:\")\n",
       "#     meus_embeddings = embeddings_real.embed_documents(minhas_frases)\n",
       "#     print(f\"‚úÖ Gerados {len(meus_embeddings)} embeddings\")\n",
       "#     \n",
       "#     # Teste de similaridade\n",
       "#     consulta_pessoal = \"Sua consulta aqui\"\n",
       "#     encontrar_frases_similares(consulta_pessoal, minhas_frases, meus_embeddings)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **ÔøΩÔøΩ M√≥dulo 2 Conclu√≠do!**\n",
       "\n",
       "### **‚úÖ O que aprendemos:**\n",
       "\n",
       "1. **üß† O que s√£o embeddings**: Transforma√ß√£o de texto em n√∫meros\n",
       "2. **üìä Similaridade**: Como calcular proximidade entre textos\n",
       "3. **üìà Visualiza√ß√£o**: Como entender rela√ß√µes entre embeddings\n",
       "4. **üöÄ Embeddings reais**: Usando modelos profissionais\n",
       "5. **üîç Busca por similaridade**: Encontrando textos relacionados\n",
       "\n",
       "### **ÔøΩÔøΩ Pr√≥ximos Passos:**\n",
       "\n",
       "No pr√≥ximo m√≥dulo vamos aprender sobre **Vector Stores** - onde guardar todos esses embeddings de forma eficiente!\n",
       "\n",
       "### **üí° Dicas Importantes:**\n",
       "\n",
       "- **Embeddings capturam significado** - n√£o apenas palavras\n",
       "- **Similaridade cosseno** √© a m√©trica mais usada\n",
       "- **Dimens√µes maiores** = mais precis√£o (mas mais lento)\n",
       "- **Modelos pr√©-treinados** s√£o melhores que treinar do zero\n",
       "\n",
       "---\n",
       "\n",
       "**üéØ Desafio do M√≥dulo**: Crie embeddings para suas pr√≥prias frases!\n",
       "\n",
       "**üí° Dica do Pedro**: Embeddings s√£o como GPS para palavras - cada palavra tem suas coordenadas no espa√ßo!\n",
       "\n",
       "**üöÄ Pr√≥ximo m√≥dulo**: Vector Stores - A mem√≥ria inteligente!"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }