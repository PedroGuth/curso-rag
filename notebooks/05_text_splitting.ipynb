{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# üìù **M√≥dulo 5: Text Splitting - Quebrando Textos Inteligentemente**\n",
       "\n",
       "> *Como cortar um bolo em peda√ßos que fazem sentido*\n",
       "\n",
       "---\n",
       "\n",
       "## **Aula 5.1: Splitting B√°sico - Como Dividir Documentos**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas por que precisamos quebrar textos?**\n",
       "\n",
       "Imagine que voc√™ tem um livro de 500 p√°ginas e quer que a IA entenda cada cap√≠tulo. Voc√™ n√£o vai jogar o livro inteiro de uma vez! Voc√™ vai **dividir em peda√ßos que fazem sentido** - como cortar um bolo em fatias.\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um livro sendo cortado em peda√ßos organizados\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "**‚ö†Ô∏è IMPORTANTE**: Se voc√™ n√£o executou o notebook `00_setup_colab.ipynb` primeiro, execute a c√©lula abaixo para instalar as depend√™ncias."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üöÄ SETUP GRATUITO PARA COLAB\n",
       "# Execute esta c√©lula primeiro para configurar o ambiente!\n",
       "\n",
       "# Instalando depend√™ncias (execute apenas se necess√°rio)\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install tiktoken>=0.5.0\n",
       "!pip install nltk>=3.8.0\n",
       "!pip install spacy>=3.7.0\n",
       "\n",
       "print(\"‚úÖ Depend√™ncias instaladas com sucesso!\")\n",
       "print(\"üöÄ Ambiente configurado para Text Splitting!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üìù IMPORTA√á√ïES PARA TEXT SPLITTING\n",
       "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
       "from langchain.text_splitter import TokenTextSplitter\n",
       "from langchain.text_splitter import CharacterTextSplitter\n",
       "from langchain.text_splitter import MarkdownTextSplitter\n",
       "from langchain.text_splitter import HTMLTextSplitter\n",
       "\n",
       "import tiktoken\n",
       "import nltk\n",
       "from nltk.tokenize import sent_tokenize, word_tokenize\n",
       "\n",
       "# Download recursos do NLTK (execute apenas uma vez)\n",
       "try:\n",
       "    nltk.data.find('tokenizers/punkt')\n",
       "except LookupError:\n",
       "    nltk.download('punkt')\n",
       "\n",
       "print(\"‚úÖ Text Splitters importados com sucesso!\")\n",
       "print(\"üî™ Pronto para quebrar textos inteligentemente!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo Pr√°tico - Texto de Exemplo**\n",
       "\n",
       "Vamos criar um texto longo para demonstrar as diferentes t√©cnicas de splitting:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ EXEMPLO PR√ÅTICO: TEXTO LONGO PARA TESTES\n",
       "\n",
       "texto_longo = \"\"\"\n",
       "# Introdu√ß√£o ao RAG - Retrieval Augmented Generation\n",
       "\n",
       "## O que √© RAG?\n",
       "\n",
       "RAG √© uma t√©cnica revolucion√°ria que combina busca de informa√ß√µes com gera√ß√£o de texto. Em vez de gerar respostas baseadas apenas no conhecimento pr√©vio, o RAG consulta documentos relevantes antes de responder.\n",
       "\n",
       "## Por que RAG √© importante?\n",
       "\n",
       "### 1. Respostas mais precisas\n",
       "RAG permite que sistemas de IA forne√ßam respostas baseadas em informa√ß√µes atualizadas e espec√≠ficas, reduzindo significativamente as alucina√ß√µes.\n",
       "\n",
       "### 2. Capacidade de usar informa√ß√µes privadas\n",
       "Diferente dos LLMs tradicionais, o RAG pode acessar e usar documentos privados, manuais t√©cnicos, e informa√ß√µes espec√≠ficas da empresa.\n",
       "\n",
       "### 3. Flexibilidade para diferentes dom√≠nios\n",
       "O RAG pode ser adaptado para qualquer dom√≠nio - desde medicina at√© engenharia, passando por direito e educa√ß√£o.\n",
       "\n",
       "## Componentes principais do RAG\n",
       "\n",
       "### Document Loaders\n",
       "Os Document Loaders s√£o respons√°veis por carregar informa√ß√µes de diferentes fontes. Eles podem ler PDFs, websites, documentos Word, e muito mais. √â como ter um \"gar√ßom universal\" que sabe ler qualquer tipo de menu.\n",
       "\n",
       "### Embeddings\n",
       "Embeddings transformam texto em n√∫meros que representam o significado das palavras. √â como criar um \"mapa\" onde palavras similares ficam pr√≥ximas umas das outras. Por exemplo, \"gato\" e \"felino\" teriam embeddings similares.\n",
       "\n",
       "### Vector Stores\n",
       "Vector Stores s√£o bancos de dados especializados em armazenar e buscar embeddings rapidamente. √â como uma biblioteca organizada por temas, onde voc√™ pode encontrar livros similares instantaneamente.\n",
       "\n",
       "### LLMs (Large Language Models)\n",
       "Os LLMs s√£o os modelos que geram as respostas finais. Eles recebem os documentos relevantes encontrados pelo sistema e geram uma resposta coerente e informativa.\n",
       "\n",
       "## Fluxo completo do RAG\n",
       "\n",
       "1. **Carregamento**: Documentos s√£o carregados usando Document Loaders\n",
       "2. **Divis√£o**: Textos longos s√£o divididos em peda√ßos menores (chunks)\n",
       "3. **Embedding**: Cada chunk √© convertido em um vetor num√©rico\n",
       "4. **Armazenamento**: Os vetores s√£o armazenados em uma Vector Store\n",
       "5. **Busca**: Quando uma pergunta √© feita, o sistema busca chunks similares\n",
       "6. **Gera√ß√£o**: O LLM gera uma resposta baseada nos chunks encontrados\n",
       "\n",
       "## Vantagens do RAG\n",
       "\n",
       "### Precis√£o\n",
       "RAG fornece respostas mais precisas porque baseia suas respostas em documentos espec√≠ficos e relevantes.\n",
       "\n",
       "### Atualiza√ß√£o\n",
       "Informa√ß√µes podem ser atualizadas simplesmente adicionando novos documentos ao sistema.\n",
       "\n",
       "### Transpar√™ncia\n",
       "√â poss√≠vel rastrear quais documentos foram usados para gerar cada resposta.\n",
       "\n",
       "### Escalabilidade\n",
       "O sistema pode lidar com grandes volumes de documentos sem perder performance.\n",
       "\n",
       "## Casos de uso comuns\n",
       "\n",
       "### Suporte ao cliente\n",
       "Sistemas RAG podem responder perguntas sobre produtos, pol√≠ticas e procedimentos da empresa.\n",
       "\n",
       "### Pesquisa acad√™mica\n",
       "Pesquisadores podem fazer perguntas sobre papers cient√≠ficos e receber respostas baseadas em literatura espec√≠fica.\n",
       "\n",
       "### Documenta√ß√£o t√©cnica\n",
       "Desenvolvedores podem consultar documenta√ß√£o t√©cnica e receber respostas precisas sobre APIs e frameworks.\n",
       "\n",
       "### An√°lise legal\n",
       "Advogados podem consultar leis, regulamentos e precedentes para obter insights relevantes.\n",
       "\n",
       "## Desafios e considera√ß√µes\n",
       "\n",
       "### Qualidade dos documentos\n",
       "A qualidade das respostas depende diretamente da qualidade dos documentos de entrada.\n",
       "\n",
       "### Overlap de contexto\n",
       "√â importante configurar adequadamente o tamanho dos chunks e o overlap para preservar contexto.\n",
       "\n",
       "### Custo computacional\n",
       "Sistemas RAG podem ser computacionalmente intensivos, especialmente com grandes volumes de dados.\n",
       "\n",
       "### Lat√™ncia\n",
       "A busca em vector stores pode introduzir lat√™ncia, especialmente em sistemas com muitos documentos.\n",
       "\n",
       "## Conclus√£o\n",
       "\n",
       "RAG representa um avan√ßo significativo na capacidade dos sistemas de IA de fornecer respostas precisas e informativas. Ao combinar busca inteligente com gera√ß√£o de texto, o RAG oferece uma solu√ß√£o robusta para aplica√ß√µes que requerem conhecimento espec√≠fico e atualizado.\n",
       "\n",
       "A chave para o sucesso com RAG est√° na compreens√£o de cada componente e na configura√ß√£o adequada do sistema para o caso de uso espec√≠fico.\n",
       "\"\"\"\n",
       "\n",
       "print(\"‚úÖ Texto longo criado com sucesso!\")\n",
       "print(f\"üìè Tamanho do texto: {len(texto_longo)} caracteres\")\n",
       "print(f\"üìÑ Aproximadamente {len(texto_longo.split())} palavras\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **1. Character Text Splitter - O Mais Simples**\n",
       "\n",
       "Vamos come√ßar com o splitter mais b√°sico - ele simplesmente conta caracteres:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CHARACTER TEXT SPLITTER - O MAIS SIMPLES\n",
       "\n",
       "# Criando o splitter\n",
       "character_splitter = CharacterTextSplitter(\n",
       "    separator=\"\\n\",  # Quebra por quebras de linha\n",
       "    chunk_size=500,  # Tamanho m√°ximo de cada chunk\n",
       "    chunk_overlap=50,  # Sobreposi√ß√£o entre chunks\n",
       "    length_function=len  # Fun√ß√£o para medir tamanho\n",
       ")\n",
       "\n",
       "# Dividindo o texto\n",
       "chunks = character_splitter.split_text(texto_longo)\n",
       "\n",
       "print(f\"üî™ Texto dividido em {len(chunks)} chunks\")\n",
       "print(f\"üìè Tamanho m√©dio dos chunks: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} caracteres\")\n",
       "\n",
       "# Mostrando alguns chunks\n",
       "for i, chunk in enumerate(chunks[:3]):\n",
       "    print(f\"\\nüìÑ Chunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Conte√∫do: {chunk[:200]}...\")\n",
       "    print(\"-\" * 50)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **2. Recursive Character Text Splitter - O Mais Inteligente**\n",
       "\n",
       "Este √© o splitter mais usado no RAG. Ele tenta quebrar o texto de forma inteligente, respeitando a estrutura:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üî™ RECURSIVE CHARACTER TEXT SPLITTER - O MAIS INTELIGENTE\n",
       "\n",
       "# Criando o splitter recursivo\n",
       "recursive_splitter = RecursiveCharacterTextSplitter(\n",
       "    chunk_size=500,  # Tamanho m√°ximo de cada chunk\n",
       "    chunk_overlap=50,  # Sobreposi√ß√£o entre chunks\n",
       "    length_function=len,  # Fun√ß√£o para medir tamanho\n",
       "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]  # Ordem de prioridade para quebrar\n",
       ")\n",
       "\n",
       "# Dividindo o texto\n",
       "chunks = recursive_splitter.split_text(texto_longo)\n",
       "\n",
       "print(f\"üî™ Texto dividido em {len(chunks)} chunks\")\n",
       "print(f\"üìè Tamanho m√©dio dos chunks: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} caracteres\")\n",
       "\n",
       "# Mostrando alguns chunks\n",
       "for i, chunk in enumerate(chunks[:3]):\n",
       "    print(f\"\\nüìÑ Chunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Conte√∫do: {chunk[:200]}...\")\n",
       "    print(\"-\" * 50)\n",
       "\n",
       "# Comparando com o anterior\n",
       "print(f\"\\nüîÑ Compara√ß√£o:\")\n",
       "print(f\"Character Splitter: {len(character_splitter.split_text(texto_longo))} chunks\")\n",
       "print(f\"Recursive Splitter: {len(chunks)} chunks\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **3. Token Text Splitter - Baseado em Tokens**\n",
       "\n",
       "Este splitter usa tokens (unidades de texto) em vez de caracteres, o que √© mais preciso para LLMs:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üî™ TOKEN TEXT SPLITTER - BASEADO EM TOKENS\n",
       "\n",
       "# Criando o splitter de tokens\n",
       "token_splitter = TokenTextSplitter(\n",
       "    chunk_size=100,  # N√∫mero m√°ximo de tokens por chunk\n",
       "    chunk_overlap=20,  # Sobreposi√ß√£o em tokens\n",
       "    encoding_name=\"cl100k_base\"  # Encoding do GPT-4\n",
       ")\n",
       "\n",
       "# Dividindo o texto\n",
       "chunks = token_splitter.split_text(texto_longo)\n",
       "\n",
       "print(f\"üî™ Texto dividido em {len(chunks)} chunks\")\n",
       "print(f\"üìè Tamanho m√©dio dos chunks: {sum(len(chunk.split()) for chunk in chunks) / len(chunks):.0f} palavras\")\n",
       "\n",
       "# Mostrando alguns chunks\n",
       "for i, chunk in enumerate(chunks[:3]):\n",
       "    print(f\"\\nüìÑ Chunk {i+1}:\")\n",
       "    print(f\"Palavras: {len(chunk.split())}\")\n",
       "    print(f\"Conte√∫do: {chunk[:200]}...\")\n",
       "    print(\"-\" * 50)\n",
       "\n",
       "# Comparando diferentes encodings\n",
       "encodings = [\"cl100k_base\", \"gpt2\"]\n",
       "for encoding in encodings:\n",
       "    splitter = TokenTextSplitter(chunk_size=100, encoding_name=encoding)\n",
       "    chunks = splitter.split_text(texto_longo)\n",
       "    print(f\"Encoding {encoding}: {len(chunks)} chunks\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "---\n",
       "\n",
       "## **Aula 5.2: Splitting Avan√ßado - Preservando Contexto**\n",
       "\n",
       "---\n",
       "\n",
       "### **Por que Overlap √© importante?**\n",
       "\n",
       "Imagine que voc√™ est√° cortando um filme em cenas. Se voc√™ cortar exatamente no meio de uma frase, perde o contexto! O **overlap** garante que informa√ß√µes importantes n√£o sejam perdidas.\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Cenas de filme com sobreposi√ß√£o para manter continuidade\n",
       "\n",
       "### **1. Configurando Overlap Inteligente**\n",
       "\n",
       "Vamos ver como o overlap afeta a qualidade dos chunks:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ OVERLAP INTELIGENTE - PRESERVANDO CONTEXTO\n",
       "\n",
       "# Testando diferentes configura√ß√µes de overlap\n",
       "overlaps = [0, 50, 100, 200]\n",
       "\n",
       "for overlap in overlaps:\n",
       "    print(f\"\\nüîÑ Testando overlap de {overlap} caracteres:\")\n",
       "    \n",
       "    splitter = RecursiveCharacterTextSplitter(\n",
       "        chunk_size=500,\n",
       "        chunk_overlap=overlap,\n",
       "        separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
       "    )\n",
       "    \n",
       "    chunks = splitter.split_text(texto_longo)\n",
       "    \n",
       "    print(f\"   üìÑ N√∫mero de chunks: {len(chunks)}\")\n",
       "    print(f\"   üìè Tamanho m√©dio: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} caracteres\")\n",
       "    \n",
       "    # Verificando sobreposi√ß√£o real\n",
       "    if len(chunks) > 1:\n",
       "        overlap_real = len(set(chunks[0][-100:]) & set(chunks[1][:100]))\n",
       "        print(f\"   ÔøΩÔøΩ Sobreposi√ß√£o real: ~{overlap_real} caracteres\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **2. Splitters Especializados por Tipo de Documento**\n",
       "\n",
       "Diferentes tipos de documento precisam de estrat√©gias diferentes de splitting:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ SPLITTERS ESPECIALIZADOS POR TIPO DE DOCUMENTO\n",
       "\n",
       "# Markdown Splitter - para documentos com formata√ß√£o\n",
       "markdown_text = \"\"\"\n",
       "# T√≠tulo Principal\n",
       "\n",
       "## Subt√≠tulo 1\n",
       "Este √© um par√°grafo com **texto em negrito** e *texto em it√°lico*.\n",
       "\n",
       "### Sub-subt√≠tulo\n",
       "- Item 1\n",
       "- Item 2\n",
       "- Item 3\n",
       "\n",
       "## Subt√≠tulo 2\n",
       "Outro par√°grafo com `c√≥digo inline` e [links](https://exemplo.com).\n",
       "\n",
       "```python\n",
       "# Bloco de c√≥digo\n",
       "def exemplo():\n",
       "    return \"Hello World\"\n",
       "```\n",
       "\"\"\"\n",
       "\n",
       "markdown_splitter = MarkdownTextSplitter(chunk_size=300, chunk_overlap=50)\n",
       "markdown_chunks = markdown_splitter.split_text(markdown_text)\n",
       "\n",
       "print(\"üìÑ Markdown Splitter:\")\n",
       "for i, chunk in enumerate(markdown_chunks):\n",
       "    print(f\"\\nChunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Conte√∫do: {chunk[:150]}...\")\n",
       "    print(\"-\" * 30)\n",
       "\n",
       "# HTML Splitter - para p√°ginas web\n",
       "html_text = \"\"\"\n",
       "<html>\n",
       "<head><title>P√°gina de Exemplo</title></head>\n",
       "<body>\n",
       "<h1>T√≠tulo Principal</h1>\n",
       "<p>Este √© um par√°grafo com <strong>texto em negrito</strong>.</p>\n",
       "<div>\n",
       "<h2>Subt√≠tulo</h2>\n",
       "<p>Outro par√°grafo com <em>texto em it√°lico</em>.</p>\n",
       "</div>\n",
       "</body>\n",
       "</html>\n",
       "\"\"\"\n",
       "\n",
       "html_splitter = HTMLTextSplitter(chunk_size=200, chunk_overlap=30)\n",
       "html_chunks = html_splitter.split_text(html_text)\n",
       "\n",
       "print(\"\\nÔøΩÔøΩ HTML Splitter:\")\n",
       "for i, chunk in enumerate(html_chunks):\n",
       "    print(f\"\\nChunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Conte√∫do: {chunk[:150]}...\")\n",
       "    print(\"-\" * 30)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **3. Splitting com Preserva√ß√£o de Estrutura**\n",
       "\n",
       "Vamos criar um splitter que preserva a estrutura hier√°rquica do documento:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üèóÔ∏è SPLITTING COM PRESERVA√á√ÉO DE ESTRUTURA\n",
       "\n",
       "def split_preserving_structure(text, chunk_size=500):\n",
       "    \"\"\"\n",
       "    Splitter que tenta preservar a estrutura hier√°rquica do documento\n",
       "    \"\"\"\n",
       "    lines = text.split('\\n')\n",
       "    chunks = []\n",
       "    current_chunk = \"\"\n",
       "    \n",
       "    for line in lines:\n",
       "        # Se a linha atual + a nova linha exceder o tamanho\n",
       "        if len(current_chunk) + len(line) > chunk_size and current_chunk:\n",
       "            chunks.append(current_chunk.strip())\n",
       "            current_chunk = line + '\\n'\n",
       "        else:\n",
       "            current_chunk += line + '\\n'\n",
       "    \n",
       "    # Adiciona o √∫ltimo chunk\n",
       "    if current_chunk.strip():\n",
       "        chunks.append(current_chunk.strip())\n",
       "    \n",
       "    return chunks\n",
       "\n",
       "# Testando o splitter personalizado\n",
       "structured_chunks = split_preserving_structure(texto_longo, chunk_size=600)\n",
       "\n",
       "print(\"ÔøΩÔøΩÔ∏è Splitter com Preserva√ß√£o de Estrutura:\")\n",
       "for i, chunk in enumerate(structured_chunks[:3]):\n",
       "    print(f\"\\nChunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Linhas: {chunk.count(chr(10)) + 1}\")\n",
       "    print(f\"Conte√∫do: {chunk[:200]}...\")\n",
       "    print(\"-\" * 50)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **4. An√°lise de Qualidade dos Chunks**\n",
       "\n",
       "Vamos criar uma fun√ß√£o para analisar a qualidade dos chunks gerados:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üìä AN√ÅLISE DE QUALIDADE DOS CHUNKS\n",
       "\n",
       "def analisar_chunks(chunks, texto_original):\n",
       "    \"\"\"\n",
       "    Analisa a qualidade dos chunks gerados\n",
       "    \"\"\"\n",
       "    print(f\"üìä An√°lise de Qualidade:\")\n",
       "    print(f\"   üìÑ N√∫mero de chunks: {len(chunks)}\")\n",
       "    print(f\"   üìè Tamanho m√©dio: {sum(len(chunk) for chunk in chunks) / len(chunks):.0f} caracteres\")\n",
       "    print(f\"   üìè Tamanho m√≠nimo: {min(len(chunk) for chunk in chunks)} caracteres\")\n",
       "    print(f\"   üìè Tamanho m√°ximo: {max(len(chunk) for chunk in chunks)} caracteres\")\n",
       "    \n",
       "    # Verificando se todo o texto original est√° coberto\n",
       "    texto_coberto = \"\".join(chunks)\n",
       "    cobertura = len(texto_coberto) / len(texto_original) * 100\n",
       "    print(f\"   ÔøΩÔøΩ Cobertura do texto original: {cobertura:.1f}%\")\n",
       "    \n",
       "    # Verificando chunks vazios ou muito pequenos\n",
       "    chunks_pequenos = [chunk for chunk in chunks if len(chunk.strip()) < 50]\n",
       "    print(f\"   ‚ö†Ô∏è Chunks muito pequenos (< 50 chars): {len(chunks_pequenos)}\")\n",
       "    \n",
       "    # Verificando chunks que come√ßam/terminam no meio de frases\n",
       "    chunks_quebrados = 0\n",
       "    for chunk in chunks:\n",
       "        if chunk and not chunk[0].isupper() and not chunk[0].isspace():\n",
       "            chunks_quebrados += 1\n",
       "        if chunk and not chunk[-1] in '.!?':\n",
       "            chunks_quebrados += 1\n",
       "    \n",
       "    print(f\"   üîó Chunks quebrados no meio de frases: {chunks_quebrados}\")\n",
       "    \n",
       "    return {\n",
       "        'num_chunks': len(chunks),\n",
       "        'tamanho_medio': sum(len(chunk) for chunk in chunks) / len(chunks),\n",
       "        'cobertura': cobertura,\n",
       "        'chunks_pequenos': len(chunks_pequenos),\n",
       "        'chunks_quebrados': chunks_quebrados\n",
       "    }\n",
       "\n",
       "# Testando diferentes configura√ß√µes\n",
       "configuracoes = [\n",
       "    (\"Recursive (500/50)\", RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)),\n",
       "    (\"Recursive (300/100)\", RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=100)),\n",
       "    (\"Character (500/50)\", CharacterTextSplitter(chunk_size=500, chunk_overlap=50)),\n",
       "    (\"Token (100/20)\", TokenTextSplitter(chunk_size=100, chunk_overlap=20))\n",
       "]\n",
       "\n",
       "print(\"üî¨ Compara√ß√£o de Configura√ß√µes de Splitting:\\n\")\n",
       "\n",
       "for nome, splitter in configuracoes:\n",
       "    print(f\"ÔøΩÔøΩ {nome}:\")\n",
       "    chunks = splitter.split_text(texto_longo)\n",
       "    analise = analisar_chunks(chunks, texto_longo)\n",
       "    print()"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **5. Exemplo Pr√°tico: An√°lise de Contratos Legais**\n",
       "\n",
       "Vamos simular um caso real - an√°lise de contratos legais que precisam preservar contexto:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ‚öñÔ∏è EXEMPLO PR√ÅTICO: AN√ÅLISE DE CONTRATOS LEGAIS\n",
       "\n",
       "# Simulando um contrato legal\n",
       "contrato_exemplo = \"\"\"\n",
       "CONTRATO DE PRESTA√á√ÉO DE SERVI√áOS\n",
       "\n",
       "1. OBJETO DO CONTRATO\n",
       "1.1. O presente contrato tem por objeto a presta√ß√£o de servi√ßos de consultoria em tecnologia da informa√ß√£o pela CONTRATADA em favor da CONTRATANTE.\n",
       "\n",
       "1.2. Os servi√ßos ser√£o prestados conforme especifica√ß√µes t√©cnicas detalhadas no Anexo I, que faz parte integrante deste contrato.\n",
       "\n",
       "2. PRAZO DE EXECU√á√ÉO\n",
       "2.1. O prazo para execu√ß√£o dos servi√ßos ser√° de 12 (doze) meses, contados a partir da data de assinatura deste contrato.\n",
       "\n",
       "2.2. O prazo poder√° ser prorrogado mediante acordo entre as partes, desde que justificado e documentado.\n",
       "\n",
       "3. VALOR E FORMA DE PAGAMENTO\n",
       "3.1. O valor total dos servi√ßos √© de R$ 100.000,00 (cem mil reais), a ser pago em 12 parcelas mensais de R$ 8.333,33 (oito mil, trezentos e trinta e tr√™s reais e trinta e tr√™s centavos).\n",
       "\n",
       "3.2. O pagamento ser√° realizado at√© o dia 10 de cada m√™s, mediante emiss√£o de nota fiscal pela CONTRATADA.\n",
       "\n",
       "4. OBRIGA√á√ïES DA CONTRATADA\n",
       "4.1. Executar os servi√ßos com a m√°xima dilig√™ncia e efici√™ncia, observando as melhores pr√°ticas do mercado.\n",
       "\n",
       "4.2. Manter sigilo sobre informa√ß√µes confidenciais da CONTRATANTE.\n",
       "\n",
       "4.3. Fornecer relat√≥rios mensais de progresso dos servi√ßos.\n",
       "\n",
       "5. OBRIGA√á√ïES DA CONTRATANTE\n",
       "5.1. Fornecer todas as informa√ß√µes necess√°rias para a execu√ß√£o dos servi√ßos.\n",
       "\n",
       "5.2. Realizar os pagamentos nos prazos estabelecidos.\n",
       "\n",
       "5.3. Designar um representante para acompanhar a execu√ß√£o dos servi√ßos.\n",
       "\n",
       "6. RESCIS√ÉO\n",
       "6.1. Este contrato poder√° ser rescindido por qualquer das partes mediante aviso pr√©vio de 30 (trinta) dias.\n",
       "\n",
       "6.2. Em caso de descumprimento das obriga√ß√µes por qualquer das partes, o contrato poder√° ser rescindido imediatamente.\n",
       "\n",
       "7. DISPOSI√á√ïES GERAIS\n",
       "7.1. Este contrato ser√° regido pelas leis brasileiras.\n",
       "\n",
       "7.2. As partes elegem o foro da comarca de S√£o Paulo para dirimir quaisquer d√∫vidas ou lit√≠gios.\n",
       "\n",
       "S√£o Paulo, 15 de janeiro de 2024.\n",
       "\n",
       "CONTRATANTE: Empresa XYZ Ltda.\n",
       "CNPJ: 12.345.678/0001-90\n",
       "Representante: Jo√£o Silva\n",
       "\n",
       "CONTRATADA: Consultoria Tech Ltda.\n",
       "CNPJ: 98.765.432/0001-10\n",
       "Representante: Maria Santos\n",
       "\"\"\"\n",
       "\n",
       "# Splitter otimizado para contratos legais\n",
       "contrato_splitter = RecursiveCharacterTextSplitter(\n",
       "    chunk_size=400,\n",
       "    chunk_overlap=100,\n",
       "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
       ")\n",
       "\n",
       "chunks_contrato = contrato_splitter.split_text(contrato_exemplo)\n",
       "\n",
       "print(\"‚öñÔ∏è An√°lise de Contrato Legal:\")\n",
       "print(f\"üìÑ Contrato dividido em {len(chunks_contrato)} chunks\\n\")\n",
       "\n",
       "for i, chunk in enumerate(chunks_contrato):\n",
       "    print(f\"üìã Chunk {i+1}:\")\n",
       "    print(f\"Tamanho: {len(chunk)} caracteres\")\n",
       "    print(f\"Conte√∫do: {chunk.strip()}\")\n",
       "    print(\"-\" * 60)\n",
       "\n",
       "# An√°lise de qualidade espec√≠fica para contratos\n",
       "print(\"\\nüìä An√°lise de Qualidade para Contratos:\")\n",
       "analisar_chunks(chunks_contrato, contrato_exemplo)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **6. Dicas e Boas Pr√°ticas**\n",
       "\n",
       "Aqui est√£o algumas dicas importantes para escolher a estrat√©gia de splitting:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üí° DICAS E BOAS PR√ÅTICAS PARA TEXT SPLITTING\n",
       "\n",
       "print(\"üí° DICAS E BOAS PR√ÅTICAS:\")\n",
       "\n",
       "dicas = [\n",
       "    {\n",
       "        \"tipo\": \"üìÑ Documentos T√©cnicos\",\n",
       "        \"splitter\": \"RecursiveCharacterTextSplitter\",\n",
       "        \"chunk_size\": \"500-800\",\n",
       "        \"overlap\": \"50-100\",\n",
       "        \"justificativa\": \"Preserva par√°grafos e se√ß√µes t√©cnicas\"\n",
       "    },\n",
       "    {\n",
       "        \"tipo\": \"‚öñÔ∏è Contratos Legais\",\n",
       "        \"splitter\": \"RecursiveCharacterTextSplitter\",\n",
       "        \"chunk_size\": \"400-600\",\n",
       "        \"overlap\": \"100-150\",\n",
       "        \"justificativa\": \"Mant√©m cl√°usulas completas e contexto legal\"\n",
       "    },\n",
       "    {\n",
       "        \"tipo\": \"üìö Livros/Acad√™mico\",\n",
       "        \"splitter\": \"RecursiveCharacterTextSplitter\",\n",
       "        \"chunk_size\": \"800-1200\",\n",
       "        \"overlap\": \"100-200\",\n",
       "        \"justificativa\": \"Preserva cap√≠tulos e se√ß√µes completas\"\n",
       "    },\n",
       "    {\n",
       "        \"tipo\": \"üåê P√°ginas Web\",\n",
       "        \"splitter\": \"HTMLTextSplitter\",\n",
       "        \"chunk_size\": \"300-500\",\n",
       "        \"overlap\": \"50-100\",\n",
       "        \"justificativa\": \"Respeita estrutura HTML e tags\"\n",
       "    },\n",
       "    {\n",
       "        \"tipo\": \"üìù C√≥digo Fonte\",\n",
       "        \"splitter\": \"RecursiveCharacterTextSplitter\",\n",
       "        \"chunk_size\": \"600-1000\",\n",
       "        \"overlap\": \"100-200\",\n",
       "        \"justificativa\": \"Mant√©m fun√ß√µes e classes completas\"\n",
       "    }\n",
       "]\n",
       "\n",
       "for dica in dicas:\n",
       "    print(f\"\\n{dica['tipo']}:\")\n",
       "    print(f\"   üîß Splitter: {dica['splitter']}\")\n",
       "    print(f\"   üìè Chunk Size: {dica['chunk_size']}\")\n",
       "    print(f\"   üîÑ Overlap: {dica['overlap']}\")\n",
       "    print(f\"   üí≠ Justificativa: {dica['justificativa']}\")\n",
       "\n",
       "print(\"\\nÔøΩÔøΩ REGRAS GERAIS:\")\n",
       "print(\"1. Sempre teste diferentes configura√ß√µes\")\n",
       "print(\"2. Monitore a qualidade dos chunks gerados\")\n",
       "print(\"3. Use overlap para preservar contexto\")\n",
       "print(\"4. Considere o tipo de documento\")\n",
       "print(\"5. Balanceie tamanho do chunk vs. n√∫mero de chunks\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **7. Exerc√≠cio Pr√°tico**\n",
       "\n",
       "Agora √© sua vez! Vamos criar um sistema de splitting personalizado:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ EXERC√çCIO PR√ÅTICO: SPLITTING PERSONALIZADO\n",
       "\n",
       "# 1. Crie um texto de exemplo (pode ser sobre qualquer assunto)\n",
       "seu_texto = \"\"\"\n",
       "[SEU TEXTO AQUI - Substitua por um texto de pelo menos 1000 caracteres]\n",
       "\n",
       "Exemplo de estrutura:\n",
       "- Introdu√ß√£o\n",
       "- Desenvolvimento com v√°rios par√°grafos\n",
       "- Conclus√£o\n",
       "- Refer√™ncias ou links\n",
       "\"\"\"\n",
       "\n",
       "# 2. Teste diferentes configura√ß√µes de RecursiveCharacterTextSplitter\n",
       "print(\"ÔøΩÔøΩ Teste 1: RecursiveCharacterTextSplitter\")\n",
       "# Sua implementa√ß√£o aqui...\n",
       "\n",
       "# 3. Compare com TokenTextSplitter\n",
       "print(\"\\nÔøΩÔøΩ Teste 2: TokenTextSplitter\")\n",
       "# Sua implementa√ß√£o aqui...\n",
       "\n",
       "# 4. Analise a qualidade dos chunks\n",
       "print(\"\\nüìä An√°lise de Qualidade\")\n",
       "# Sua implementa√ß√£o aqui...\n",
       "\n",
       "# 5. Escolha a melhor configura√ß√£o e justifique\n",
       "print(\"\\nüèÜ Melhor Configura√ß√£o\")\n",
       "print(\"Justificativa: ...\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **8. Resumo do M√≥dulo**\n",
       "\n",
       "Vamos recapitular o que aprendemos:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ RESUMO DO M√ìDULO 5: TEXT SPLITTING\n",
       "\n",
       "resumo = {\n",
       "    \"conceitos_principais\": [\n",
       "        \"Text Splitting √© essencial para processar documentos longos\",\n",
       "        \"Overlap preserva contexto entre chunks\",\n",
       "        \"Diferentes tipos de documento precisam de estrat√©gias diferentes\"\n",
       "    ],\n",
       "    \"splitters_aprendidos\": [\n",
       "        \"CharacterTextSplitter - Mais simples, baseado em caracteres\",\n",
       "        \"RecursiveCharacterTextSplitter - Mais inteligente, respeita estrutura\",\n",
       "        \"TokenTextSplitter - Baseado em tokens, ideal para LLMs\",\n",
       "        \"MarkdownTextSplitter - Para documentos com formata√ß√£o Markdown\",\n",
       "        \"HTMLTextSplitter - Para p√°ginas web\"\n",
       "    ],\n",
       "    \"parametros_importantes\": [\n",
       "        \"chunk_size - Tamanho m√°ximo de cada chunk\",\n",
       "        \"chunk_overlap - Sobreposi√ß√£o entre chunks\",\n",
       "        \"separators - Ordem de prioridade para quebrar texto\",\n",
       "        \"length_function - Como medir o tamanho do texto\"\n",
       "    ],\n",
       "    \"boas_praticas\": [\n",
       "        \"Sempre teste diferentes configura√ß√µes\",\n",
       "        \"Monitore a qualidade dos chunks\",\n",
       "        \"Use overlap para preservar contexto\",\n",
       "        \"Considere o tipo de documento\",\n",
       "        \"Balanceie tamanho vs. n√∫mero de chunks\"\n",
       "    ]\n",
       "}\n",
       "\n",
       "print(\"ÔøΩÔøΩ RESUMO DO M√ìDULO 5: TEXT SPLITTING\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for categoria, itens in resumo.items():\n",
       "    print(f\"\\nÔøΩÔøΩ {categoria.replace('_', ' ').title()}:\")\n",
       "    for item in itens:\n",
       "        print(f\"   ‚Ä¢ {item}\")\n",
       "\n",
       "print(\"\\nüöÄ Pr√≥ximo m√≥dulo: Retrieval - Encontrando as Informa√ß√µes Certas!\")\n",
       "print(\"   Vamos aprender como buscar chunks relevantes de forma eficiente!\")"
      ]
     },
     {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
         "---\n",
         "\n",
         "## **üéØ Conclus√£o do M√≥dulo**\n",
         "\n",
         "Neste m√≥dulo, aprendemos que **Text Splitting** √© como cortar um bolo em fatias que fazem sentido. N√£o √© apenas quebrar o texto, mas fazer isso de forma inteligente para preservar o contexto e a estrutura.\n",
         "\n",
         "**Principais takeaways:**\n",
         "- ‚úÖ RecursiveCharacterTextSplitter √© o mais usado no RAG\n",
         "- ‚úÖ Overlap √© crucial para preservar contexto\n",
         "- ‚úÖ Diferentes documentos precisam de estrat√©gias diferentes\n",
         "- ‚úÖ Sempre teste e analise a qualidade dos chunks\n",
         "\n",
         "**Pr√≥ximo passo:** No m√≥dulo 6, vamos aprender sobre **Retrieval** - como encontrar os chunks mais relevantes quando fazemos uma pergunta!\n",
         "\n",
         "---\n",
         "\n",
         "*üí° **Dica**: Experimente diferentes configura√ß√µes de splitting com seus pr√≥prios documentos para encontrar a que funciona melhor para seu caso de uso espec√≠fico.*"
        ]
       }
      ],
      "metadata": {
       "kernelspec": {
        "display_name": "Python 3",
        "language": "python",
        "name": "python3"
       },
       "language_info": {
        "codemirror_mode": {
         "name": "ipython",
         "version": 3
        },
        "file_extension": ".py",
        "mimetype": "text/x-python",
        "name": "python",
        "nbconvert_exporter": "python",
        "pygments_lexer": "ipython3",
        "version": "3.8.5"
       }
      },
      "nbformat": 4,
      "nbformat_minor": 4
     }