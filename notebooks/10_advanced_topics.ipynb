{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# üîÆ **M√≥dulo 10: T√≥picos Avan√ßados - Explorando o Futuro do RAG**\n",
       "\n",
       "> *Agora vamos explorar as fronteiras mais avan√ßadas do RAG!*\n",
       "\n",
       "---\n",
       "\n",
       "## **Aula 10.1: RAG Multimodal - Al√©m do Texto**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas o que √© RAG Multimodal?**\n",
       "\n",
       "RAG Multimodal √© como ter um **assistente que entende n√£o s√≥ texto, mas tamb√©m imagens, v√≠deos e √°udio**. √â como dar superpoderes ao RAG! ü¶∏‚Äç‚ôÇÔ∏è\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um assistente digital processando texto, imagens, v√≠deos e √°udio simultaneamente\n",
       "\n",
       "**Por que RAG Multimodal √© importante?**\n",
       "\n",
       "√â como a diferen√ßa entre:\n",
       "- üìù **RAG Tradicional**: S√≥ entende texto\n",
       "- üé® **RAG Multimodal**: Entende tudo (texto, imagens, v√≠deos, √°udio)\n",
       "\n",
       "### **Analogia do Dia a Dia**\n",
       "\n",
       "RAG Multimodal √© como um **detetive completo**:\n",
       "- üëÅÔ∏è **Vis√£o**: Analisa imagens e v√≠deos\n",
       "- üëÇ **Audi√ß√£o**: Processa √°udio e m√∫sica\n",
       "- üìñ **Leitura**: Entende documentos e textos\n",
       "- üß† **Intelig√™ncia**: Combina tudo para resolver casos\n",
       "\n",
       "**Sem Multimodal** seria como um detetive que s√≥ pode ler relat√≥rios! üòÖ\n",
       "\n",
       "---\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "**‚ö†Ô∏è IMPORTANTE**: Se voc√™ n√£o executou o notebook `00_setup_colab.ipynb` primeiro, execute a c√©lula abaixo para instalar as depend√™ncias."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üöÄ SETUP GRATUITO PARA COLAB\n",
       "# Execute esta c√©lula primeiro para configurar o ambiente!\n",
       "\n",
       "# Instalando depend√™ncias para RAG multimodal\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install huggingface_hub>=0.19.0\n",
       "!pip install sentence-transformers>=2.2.0\n",
       "!pip install chromadb>=0.4.0\n",
       "!pip install pillow>=10.0.0\n",
       "!pip install opencv-python>=4.8.0\n",
       "!pip install transformers>=4.35.0\n",
       "!pip install torch>=2.0.0\n",
       "!pip install torchvision>=0.15.0\n",
       "!pip install numpy>=1.24.0\n",
       "!pip install matplotlib>=3.5.0\n",
       "\n",
       "print(\"‚úÖ Depend√™ncias multimodais instaladas com sucesso!\")\n",
       "print(\"ÔøΩÔøΩ Pronto para explorar o futuro do RAG!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ IMPORTA√á√ïES PARA RAG MULTIMODAL\n",
       "import os\n",
       "import numpy as np\n",
       "import matplotlib.pyplot as plt\n",
       "from PIL import Image\n",
       "import cv2\n",
       "from dotenv import load_dotenv\n",
       "\n",
       "# LangChain\n",
       "from langchain_community.llms import HuggingFaceHub\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_community.vectorstores import Chroma\n",
       "from langchain.schema import Document\n",
       "\n",
       "# Transformers para multimodal\n",
       "from transformers import CLIPProcessor, CLIPModel\n",
       "from transformers import pipeline\n",
       "\n",
       "print(\"‚úÖ Bibliotecas multimodais importadas com sucesso!\")\n",
       "print(\"üîÆ Pronto para processar texto, imagens e mais!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo Pr√°tico - Criando Nosso Primeiro RAG Multimodal**\n",
       "\n",
       "Vamos criar um sistema RAG que pode entender tanto texto quanto imagens. √â como dar olhos ao nosso assistente! ÔøΩÔøΩÔ∏è"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üëÅÔ∏è EXEMPLO PR√ÅTICO: CRIANDO NOSSO PRIMEIRO RAG MULTIMODAL\n",
       "\n",
       "# Carregando modelo CLIP para processamento multimodal\n",
       "def carregar_modelo_clip():\n",
       "    \"\"\"Carrega o modelo CLIP para processamento de texto e imagem\"\"\"\n",
       "    try:\n",
       "        model_name = \"openai/clip-vit-base-patch32\"\n",
       "        model = CLIPModel.from_pretrained(model_name)\n",
       "        processor = CLIPProcessor.from_pretrained(model_name)\n",
       "        \n",
       "        print(f\"‚úÖ Modelo CLIP carregado: {model_name}\")\n",
       "        return model, processor\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"‚ùå Erro ao carregar CLIP: {e}\")\n",
       "        return None, None\n",
       "\n",
       "# Carregando modelo\n",
       "model_clip, processor_clip = carregar_modelo_clip()\n",
       "\n",
       "print(\"üîÆ Modelo multimodal pronto!\")\n",
       "print(\"üëÅÔ∏è Pode processar texto e imagens simultaneamente!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üé® CRIANDO BASE DE CONHECIMENTO MULTIMODAL\n",
       "\n",
       "# Base de conhecimento com texto e descri√ß√µes de imagens\n",
       "base_multimodal = [\n",
       "    {\n",
       "        \"texto\": \"Um gato laranja dormindo no sof√°\",\n",
       "        \"tipo\": \"imagem\",\n",
       "        \"descricao\": \"Gato dom√©stico de cor laranja descansando em um sof√° confort√°vel\",\n",
       "        \"tags\": [\"gato\", \"animal\", \"dormindo\", \"sof√°\", \"laranja\"]\n",
       "    },\n",
       "    {\n",
       "        \"texto\": \"Uma paisagem de montanha com neve\",\n",
       "        \"tipo\": \"imagem\",\n",
       "        \"descricao\": \"Montanhas cobertas de neve em uma paisagem natural\",\n",
       "        \"tags\": [\"montanha\", \"neve\", \"paisagem\", \"natureza\"]\n",
       "    },\n",
       "    {\n",
       "        \"texto\": \"Um carro vermelho estacionado na rua\",\n",
       "        \"tipo\": \"imagem\",\n",
       "        \"descricao\": \"Autom√≥vel vermelho estacionado em uma rua urbana\",\n",
       "        \"tags\": [\"carro\", \"vermelho\", \"estacionado\", \"rua\"]\n",
       "    },\n",
       "    {\n",
       "        \"texto\": \"RAG √© uma t√©cnica que combina busca com gera√ß√£o\",\n",
       "        \"tipo\": \"texto\",\n",
       "        \"descricao\": \"Informa√ß√£o sobre RAG e suas aplica√ß√µes\",\n",
       "        \"tags\": [\"RAG\", \"IA\", \"tecnologia\", \"busca\"]\n",
       "    },\n",
       "    {\n",
       "        \"texto\": \"Machine Learning √© um subcampo da IA\",\n",
       "        \"tipo\": \"texto\",\n",
       "        \"descricao\": \"Conceitos b√°sicos de Machine Learning\",\n",
       "        \"tags\": [\"Machine Learning\", \"IA\", \"algoritmos\", \"dados\"]\n",
       "    }\n",
       "]\n",
       "\n",
       "print(f\"üé® Base multimodal criada com {len(base_multimodal)} itens\")\n",
       "print(\"üìù Inclui texto e descri√ß√µes de imagens\")\n",
       "print(\"üîÆ Pronto para processamento multimodal!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 10.2: Processamento de Imagens com RAG**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas como o RAG entende imagens?**\n",
       "\n",
       "Vamos aprender como **transformar imagens em texto** que o RAG pode entender. √â como ensinar o RAG a \"ler\" imagens! üì∏\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Uma imagem sendo transformada em texto descritivo"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üì∏ PROCESSAMENTO DE IMAGENS COM RAG\n",
       "\n",
       "# Fun√ß√£o para gerar descri√ß√µes de imagens\n",
       "def gerar_descricao_imagem(imagem_path):\n",
       "    \"\"\"Gera descri√ß√£o de uma imagem usando IA\"\"\"\n",
       "    try:\n",
       "        # Carregando modelo de caption\n",
       "        captioner = pipeline(\"image-to-text\", model=\"nlpconnect/vit-gpt2-image-captioning\")\n",
       "        \n",
       "        # Carregando imagem\n",
       "        imagem = Image.open(imagem_path)\n",
       "        \n",
       "        # Gerando descri√ß√£o\n",
       "        resultado = captioner(imagem)\n",
       "        descricao = resultado[0]['generated_text']\n",
       "        \n",
       "        return descricao\n",
       "        \n",
       "    except Exception as e:\n",
       "        return f\"Erro ao processar imagem: {e}\"\n",
       "\n",
       "# Fun√ß√£o para criar embeddings de imagens\n",
       "def criar_embedding_imagem(imagem_path, model, processor):\n",
       "    \"\"\"Cria embedding de uma imagem usando CLIP\"\"\"\n",
       "    try:\n",
       "        # Carregando imagem\n",
       "        imagem = Image.open(imagem_path)\n",
       "        \n",
       "        # Processando imagem\n",
       "        inputs = processor(images=imagem, return_tensors=\"pt\")\n",
       "        \n",
       "        # Gerando embedding\n",
       "        with torch.no_grad():\n",
       "            image_features = model.get_image_features(**inputs)\n",
       "        \n",
       "        return image_features.numpy().flatten()\n",
       "        \n",
       "    except Exception as e:\n",
       "        print(f\"Erro ao criar embedding: {e}\")\n",
       "        return None\n",
       "\n",
       "print(\"ÔøΩÔøΩ Fun√ß√µes de processamento de imagem criadas!\")\n",
       "print(\"üîÆ Pode gerar descri√ß√µes e embeddings de imagens!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ TESTANDO PROCESSAMENTO DE IMAGENS\n",
       "\n",
       "# Criando uma imagem de exemplo (simulada)\n",
       "def criar_imagem_exemplo():\n",
       "    \"\"\"Cria uma imagem de exemplo para teste\"\"\"\n",
       "    # Criando uma imagem simples com matplotlib\n",
       "    fig, ax = plt.subplots(figsize=(6, 4))\n",
       "    ax.set_xlim(0, 10)\n",
       "    ax.set_ylim(0, 10)\n",
       "    ax.fill([2, 8, 8, 2], [2, 2, 8, 8], 'orange', alpha=0.7)\n",
       "    ax.set_title('Gato Laranja')\n",
       "    ax.set_xlabel('X')\n",
       "    ax.set_ylabel('Y')\n",
       "    \n",
       "    # Salvando imagem\n",
       "    plt.savefig('gato_exemplo.png', dpi=100, bbox_inches='tight')\n",
       "    plt.close()\n",
       "    \n",
       "    return 'gato_exemplo.png'\n",
       "\n",
       "# Criando imagem de teste\n",
       "imagem_teste = criar_imagem_exemplo()\n",
       "\n",
       "print(\"üé® Imagem de exemplo criada: 'gato_exemplo.png'\")\n",
       "print(\"ÔøΩÔøΩ Pronto para testar processamento multimodal!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 10.3: RAG com Mem√≥ria Avan√ßada**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas como fazer o RAG lembrar de conversas longas?**\n",
       "\n",
       "Vamos explorar **t√©cnicas avan√ßadas de mem√≥ria** que permitem ao RAG lembrar de conversas muito longas. √â como dar uma mem√≥ria de elefante ao RAG! üêò\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um c√©rebro com m√∫ltiplas camadas de mem√≥ria"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ RAG COM MEM√ìRIA AVAN√áADA\n",
       "\n",
       "from langchain.memory import ConversationSummaryMemory\n",
       "from langchain.memory import ConversationBufferWindowMemory\n",
       "from langchain.memory import ConversationTokenBufferMemory\n",
       "from langchain.memory import ConversationSummaryBufferMemory\n",
       "\n",
       "# Fun√ß√£o para criar diferentes tipos de mem√≥ria\n",
       "def criar_memorias_avancadas(llm):\n",
       "    \"\"\"Cria diferentes tipos de mem√≥ria avan√ßada\"\"\"\n",
       "    \n",
       "    memorias = {}\n",
       "    \n",
       "    # 1. Mem√≥ria com Resumo\n",
       "    memorias['resumo'] = ConversationSummaryMemory(\n",
       "        llm=llm,\n",
       "        memory_key=\"chat_history\",\n",
       "        return_messages=True\n",
       "    )\n",
       "    \n",
       "    # 2. Mem√≥ria com Janela (√∫ltimas N mensagens)\n",
       "    memorias['janela'] = ConversationBufferWindowMemory(\n",
       "        k=5,  # Lembra das √∫ltimas 5 mensagens\n",
       "        memory_key=\"chat_history\",\n",
       "        return_messages=True\n",
       "    )\n",
       "    \n",
       "    # 3. Mem√≥ria com Buffer de Tokens\n",
       "    memorias['tokens'] = ConversationTokenBufferMemory(\n",
       "        llm=llm,\n",
       "        max_token_limit=1000,  # Limite de 1000 tokens\n",
       "        memory_key=\"chat_history\",\n",
       "        return_messages=True\n",
       "    )\n",
       "    \n",
       "    # 4. Mem√≥ria com Resumo e Buffer\n",
       "    memorias['resumo_buffer'] = ConversationSummaryBufferMemory(\n",
       "        llm=llm,\n",
       "        max_token_limit=1000,\n",
       "        memory_key=\"chat_history\",\n",
       "        return_messages=True\n",
       "    )\n",
       "    \n",
       "    return memorias\n",
       "\n",
       "print(\"ÔøΩÔøΩ Fun√ß√µes de mem√≥ria avan√ßada criadas!\")\n",
       "print(\"üß† Pode lidar com conversas muito longas!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ TESTANDO MEM√ìRIAS AVAN√áADAS\n",
       "\n",
       "# Configurando LLM\n",
       "def get_llm_colab():\n",
       "    \"\"\"Retorna o melhor LLM dispon√≠vel no Colab\"\"\"\n",
       "    try:\n",
       "        from langchain_openai import ChatOpenAI\n",
       "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
       "        if api_key:\n",
       "            return ChatOpenAI(\n",
       "                model=\"gpt-3.5-turbo\",\n",
       "                temperature=0.7,\n",
       "                api_key=api_key\n",
       "            )\n",
       "    except:\n",
       "        pass\n",
       "    \n",
       "    return HuggingFaceHub(\n",
       "        repo_id=\"google/flan-t5-base\",\n",
       "        model_kwargs={\"temperature\": 0.7, \"max_length\": 512}\n",
       "    )\n",
       "\n",
       "llm = get_llm_colab()\n",
       "\n",
       "# Criando memorias\n",
       "memorias = criar_memorias_avancadas(llm)\n",
       "\n",
       "print(\"ÔøΩÔøΩ Memorias avan√ßadas criadas!\")\n",
       "print(f\"ÔøΩÔøΩ Tipos dispon√≠veis: {list(memorias.keys())}\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 10.4: RAG com Agentes Inteligentes**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas e se o RAG pudesse tomar decis√µes?**\n",
       "\n",
       "Vamos criar **agentes RAG** que podem tomar decis√µes e executar a√ß√µes. √â como dar um c√©rebro ao RAG! üß†\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um rob√¥ tomando decis√µes com m√∫ltiplas op√ß√µes"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß† RAG COM AGENTES INTELIGENTES\n",
       "\n",
       "from langchain.agents import initialize_agent, AgentType\n",
       "from langchain.tools import Tool\n",
       "from langchain.schema import HumanMessage\n",
       "\n",
       "# Criando ferramentas para o agente\n",
       "def criar_ferramentas_rag(vectorstore):\n",
       "    \"\"\"Cria ferramentas para o agente RAG\"\"\"\n",
       "    \n",
       "    def buscar_documentos(pergunta):\n",
       "        \"\"\"Busca documentos relevantes\"\"\"\n",
       "        docs = vectorstore.similarity_search(pergunta, k=3)\n",
       "        return [doc.page_content for doc in docs]\n",
       "    \n",
       "    def calcular_matematica(expressao):\n",
       "        \"\"\"Calcula express√µes matem√°ticas\"\"\"\n",
       "        try:\n",
       "            return eval(expressao)\n",
       "        except:\n",
       "            return \"Erro no c√°lculo\"\n",
       "    \n",
       "    def obter_data_atual():\n",
       "        \"\"\"Retorna a data atual\"\"\"\n",
       "        from datetime import datetime\n",
       "        return datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
       "    \n",
       "    # Criando ferramentas\n",
       "    ferramentas = [\n",
       "        Tool(\n",
       "            name=\"Buscar_Documentos\",\n",
       "            func=buscar_documentos,\n",
       "            description=\"Busca informa√ß√µes em documentos quando voc√™ precisa de dados espec√≠ficos\"\n",
       "        ),\n",
       "        Tool(\n",
       "            name=\"Calculadora\",\n",
       "            func=calcular_matematica,\n",
       "            description=\"Calcula express√µes matem√°ticas quando voc√™ precisa fazer contas\"\n",
       "        ),\n",
       "        Tool(\n",
       "            name=\"Data_Atual\",\n",
       "            func=obter_data_atual,\n",
       "            description=\"Retorna a data e hora atual quando voc√™ precisa dessa informa√ß√£o\"\n",
       "        )\n",
       "    ]\n",
       "    \n",
       "    return ferramentas\n",
       "\n",
       "print(\"üß† Fun√ß√µes de agente inteligente criadas!\")\n",
       "print(\"ü§ñ Pode tomar decis√µes e executar a√ß√µes!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CRIANDO O AGENTE RAG INTELIGENTE\n",
       "\n",
       "# Criando vector store simples para teste\n",
       "documentos_teste = [\n",
       "    Document(page_content=\"RAG √© uma t√©cnica revolucion√°ria para IA\", metadata={\"tipo\": \"info\"}),\n",
       "    Document(page_content=\"Machine Learning √© um subcampo da IA\", metadata={\"tipo\": \"info\"}),\n",
       "    Document(page_content=\"Python √© uma linguagem de programa√ß√£o popular\", metadata={\"tipo\": \"info\"})\n",
       "]\n",
       "\n",
       "embeddings = HuggingFaceEmbeddings(\n",
       "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
       ")\n",
       "\n",
       "vectorstore = Chroma.from_documents(\n",
       "    documents=documentos_teste,\n",
       "    embedding=embeddings,\n",
       "    collection_name=\"teste_agente\"\n",
       ")\n",
       "\n",
       "# Criando ferramentas\n",
       "ferramentas = criar_ferramentas_rag(vectorstore)\n",
       "\n",
       "# Criando agente\n",
       "agente_rag = initialize_agent(\n",
       "    tools=ferramentas,\n",
       "    llm=llm,\n",
       "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
       "    verbose=True,\n",
       "    handle_parsing_errors=True\n",
       ")\n",
       "\n",
       "print(\"ÔøΩÔøΩ Agente RAG inteligente criado!\")\n",
       "print(\"üß† Pode buscar documentos, calcular e tomar decis√µes!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 10.5: RAG com Fine-tuning Personalizado**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas e se eu quiser personalizar o RAG para meu dom√≠nio?**\n",
       "\n",
       "Vamos explorar **fine-tuning** para criar RAGs especializados. √â como treinar um especialista em uma √°rea espec√≠fica! üéØ\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um modelo sendo treinado com dados espec√≠ficos"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üéØ RAG COM FINE-TUNING PERSONALIZADO\n",
       "\n",
       "# Fun√ß√£o para criar dataset de fine-tuning\n",
       "def criar_dataset_finetuning():\n",
       "    \"\"\"Cria dataset para fine-tuning do RAG\"\"\"\n",
       "    \n",
       "    dataset = [\n",
       "        {\n",
       "            \"pergunta\": \"O que √© RAG?\",\n",
       "            \"resposta\": \"RAG (Retrieval Augmented Generation) √© uma t√©cnica que combina busca de informa√ß√µes com gera√ß√£o de texto para criar respostas mais precisas e baseadas em fatos.\",\n",
       "            \"contexto\": \"RAG √© uma t√©cnica revolucion√°ria que combina busca de informa√ß√µes com gera√ß√£o de texto.\"\n",
       "        },\n",
       "        {\n",
       "            \"pergunta\": \"Como funciona o Machine Learning?\",\n",
       "            \"resposta\": \"Machine Learning √© um subcampo da IA que permite aos computadores aprender padr√µes nos dados sem serem explicitamente programados.\",\n",
       "            \"contexto\": \"Machine Learning √© um subcampo da IA que permite aos computadores aprender sem serem explicitamente programados.\"\n",
       "        },\n",
       "        {\n",
       "            \"pergunta\": \"Quais s√£o as vantagens do RAG?\",\n",
       "            \"resposta\": \"As principais vantagens do RAG incluem: respostas mais precisas, redu√ß√£o de alucina√ß√µes, capacidade de usar informa√ß√µes privadas e flexibilidade para diferentes dom√≠nios.\",\n",
       "            \"contexto\": \"RAG permite respostas mais precisas, reduz alucina√ß√µes e pode usar informa√ß√µes privadas.\"\n",
       "        }\n",
       "    ]\n",
       "    \n",
       "    return dataset\n",
       "\n",
       "# Fun√ß√£o para avaliar qualidade das respostas\n",
       "def avaliar_resposta(resposta_gerada, resposta_esperada):\n",
       "    \"\"\"Avalia a qualidade de uma resposta\"\"\"\n",
       "    \n",
       "    # M√©tricas simples de avalia√ß√£o\n",
       "    palavras_geradas = set(resposta_gerada.lower().split())\n",
       "    palavras_esperadas = set(resposta_esperada.lower().split())\n",
       "    \n",
       "    # Similaridade de palavras\n",
       "    palavras_comuns = palavras_geradas.intersection(palavras_esperadas)\n",
       "    similaridade = len(palavras_comuns) / len(palavras_esperadas) if palavras_esperadas else 0\n",
       "    \n",
       "    return {\n",
       "        \"similaridade\": similaridade,\n",
       "        \"palavras_comuns\": len(palavras_comuns),\n",
       "        \"total_esperado\": len(palavras_esperadas)\n",
       "    }\n",
       "\n",
       "print(\"üéØ Fun√ß√µes de fine-tuning criadas!\")\n",
       "print(\"üìä Pode criar datasets e avaliar qualidade!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üìä TESTANDO FINE-TUNING E AVALIA√á√ÉO\n",
       "\n",
       "# Criando dataset\n",
       "dataset = criar_dataset_finetuning()\n",
       "\n",
       "print(\"üìä DATASET DE FINE-TUNING CRIADO\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "for i, item in enumerate(dataset, 1):\n",
       "    print(f\"\\nüìù Item {i}:\")\n",
       "    print(f\"   Pergunta: {item['pergunta']}\")\n",
       "    print(f\"   Resposta: {item['resposta'][:100]}...\")\n",
       "    print(f\"   Contexto: {item['contexto'][:80]}...\")\n",
       "\n",
       "print(f\"\\n‚úÖ Dataset criado com {len(dataset)} exemplos\")\n",
       "print(\"üéØ Pronto para fine-tuning personalizado!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 10.6: RAG em Tempo Real**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas e se eu quiser RAG que atualiza em tempo real?**\n",
       "\n",
       "Vamos criar **RAG em tempo real** que pode processar dados que chegam continuamente. √â como ter um RAG que nunca dorme! ‚ö°\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Dados fluindo em tempo real para um sistema RAG"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ‚ö° RAG EM TEMPO REAL\n",
       "\n",
       "import time\n",
       "import threading\n",
       "from queue import Queue\n",
       "\n",
       "class RAGTempoReal:\n",
       "    \"\"\"Sistema RAG que processa dados em tempo real\"\"\"\n",
       "    \n",
       "    def __init__(self, vectorstore, llm):\n",
       "        self.vectorstore = vectorstore\n",
       "        self.llm = llm\n",
       "        self.fila_dados = Queue()\n",
       "        self.processando = False\n",
       "        \n",
       "    def adicionar_dado(self, texto, metadata=None):\n",
       "        \"\"\"Adiciona novo dado √† fila de processamento\"\"\"\n",
       "        self.fila_dados.put({\n",
       "            \"texto\": texto,\n",
       "            \"metadata\": metadata or {},\n",
       "            \"timestamp\": time.time()\n",
       "        })\n",
       "        print(f\"üì• Dado adicionado √† fila: {texto[:50]}...\")\n",
       "    \n",
       "    def processar_dados(self):\n",
       "        \"\"\"Processa dados da fila em tempo real\"\"\"\n",
       "        self.processando = True\n",
       "        \n",
       "        while self.processando:\n",
       "            try:\n",
       "                # Pegando dado da fila (timeout de 1 segundo)\n",
       "                dado = self.fila_dados.get(timeout=1)\n",
       "                \n",
       "                # Processando dado\n",
       "                doc = Document(\n",
       "                    page_content=dado[\"texto\"],\n",
       "                    metadata=dado[\"metadata\"]\n",
       "                )\n",
       "                \n",
       "                # Adicionando ao vector store\n",
       "                self.vectorstore.add_documents([doc])\n",
       "                \n",
       "                print(f\"‚ö° Dado processado: {dado['texto'][:50]}...\")\n",
       "                \n",
       "            except:\n",
       "                # Timeout - continua processando\n",
       "                continue\n",
       "    \n",
       "    def iniciar_processamento(self):\n",
       "        \"\"\"Inicia o processamento em background\"\"\"\n",
       "        thread = threading.Thread(target=self.processar_dados)\n",
       "        thread.daemon = True\n",
       "        thread.start()\n",
       "        print(\"‚ö° Processamento em tempo real iniciado!\")\n",
       "    \n",
       "    def parar_processamento(self):\n",
       "        \"\"\"Para o processamento\"\"\"\n",
       "        self.processando = False\n",
       "        print(\"‚èπÔ∏è Processamento parado!\")\n",
       "    \n",
       "    def perguntar_tempo_real(self, pergunta):\n",
       "        \"\"\"Faz pergunta considerando dados em tempo real\"\"\"\n",
       "        try:\n",
       "            docs = self.vectorstore.similarity_search(pergunta, k=3)\n",
       "            contexto = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
       "            \n",
       "            prompt = f\"\"\"\n",
       "            Responda √† pergunta usando o contexto (que inclui dados em tempo real):\n",
       "            \n",
       "            CONTEXTO: {contexto}\n",
       "            PERGUNTA: {pergunta}\n",
       "            \"\"\"\n",
       "            \n",
       "            response = self.llm.invoke([HumanMessage(content=prompt)])\n",
       "            return response.content\n",
       "            \n",
       "        except Exception as e:\n",
       "            return f\"Erro: {e}\"\n",
       "\n",
       "print(\"‚ö° Sistema RAG em tempo real criado!\")\n",
       "print(\"üîÑ Pode processar dados continuamente!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß™ TESTANDO RAG EM TEMPO REAL\n",
       "\n",
       "# Criando sistema RAG em tempo real\n",
       "rag_tempo_real = RAGTempoReal(vectorstore, llm)\n",
       "\n",
       "# Iniciando processamento\n",
       "rag_tempo_real.iniciar_processamento()\n",
       "\n",
       "print(\"üß™ TESTANDO RAG EM TEMPO REAL\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "# Adicionando dados em tempo real\n",
       "dados_tempo_real = [\n",
       "    \"Novo produto lan√ßado: Smartphone XYZ com c√¢mera de 108MP\",\n",
       "    \"Atualiza√ß√£o de seguran√ßa: Patch cr√≠tico para sistema Android\",\n",
       "    \"Tend√™ncia de mercado: IA generativa cresce 300% este ano\",\n",
       "    \"Not√≠cia urgente: Nova tecnologia de bateria revoluciona smartphones\"\n",
       "]\n",
       "\n",
       "for dado in dados_tempo_real:\n",
       "    rag_tempo_real.adicionar_dado(dado)\n",
       "    time.sleep(1)  # Simulando chegada de dados\n",
       "\n",
       "print(\"\\nüìä Dados adicionados em tempo real!\")\n",
       "print(\"‚ö° Sistema processando continuamente!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Desafio do M√≥dulo - Criando um Sistema RAG Futurista**\n",
       "\n",
       "Vamos criar um sistema que combina todas as t√©cnicas avan√ßadas:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ DESAFIO: SISTEMA RAG FUTURISTA\n",
       "\n",
       "class SistemaRAGFuturista:\n",
       "    \"\"\"Sistema RAG que combina todas as t√©cnicas avan√ßadas\"\"\"\n",
       "    \n",
       "    def __init__(self, llm):\n",
       "        self.llm = llm\n",
       "        self.vectorstore = None\n",
       "        self.memoria = None\n",
       "        self.agente = None\n",
       "        self.rag_tempo_real = None\n",
       "        \n",
       "    def configurar_multimodal(self):\n",
       "        \"\"\"Configura capacidades multimodais\"\"\"\n",
       "        print(\"ÔøΩÔøΩ Configurando capacidades multimodais...\")\n",
       "        # Aqui voc√™ adicionaria configura√ß√£o de CLIP e outros modelos\n",
       "        \n",
       "    def configurar_memoria_avancada(self):\n",
       "        \"\"\"Configura mem√≥ria avan√ßada\"\"\"\n",
       "        print(\"üêò Configurando mem√≥ria avan√ßada...\")\n",
       "        self.memoria = ConversationSummaryBufferMemory(\n",
       "            llm=self.llm,\n",
       "            max_token_limit=2000,\n",
       "            memory_key=\"chat_history\",\n",
       "            return_messages=True\n",
       "        )\n",
       "        \n",
       "    def configurar_agente(self):\n",
       "        \"\"\"Configura agente inteligente\"\"\"\n",
       "        print(\"ü§ñ Configurando agente inteligente...\")\n",
       "        # Aqui voc√™ configuraria o agente com ferramentas\n",
       "        \n",
       "    def configurar_tempo_real(self):\n",
       "        \"\"\"Configura processamento em tempo real\"\"\"\n",
       "        print(\"‚ö° Configurando processamento em tempo real...\")\n",
       "        # Aqui voc√™ configuraria o sistema em tempo real\n",
       "        \n",
       "    def inicializar_sistema(self):\n",
       "        \"\"\"Inicializa todo o sistema futurista\"\"\"\n",
       "        print(\"ÔøΩÔøΩ INICIALIZANDO SISTEMA RAG FUTURISTA\")\n",
       "        print(\"=\" * 50)\n",
       "        \n",
       "        self.configurar_multimodal()\n",
       "        self.configurar_memoria_avancada()\n",
       "        self.configurar_agente()\n",
       "        self.configurar_tempo_real()\n",
       "        \n",
       "        print(\"\\nüéâ Sistema RAG Futurista inicializado!\")\n",
       "        print(\"ÔøΩÔøΩ Capacidades ativas:\")\n",
       "        print(\"   - Multimodal (texto + imagem)\")\n",
       "        print(\"   - Mem√≥ria avan√ßada\")\n",
       "        print(\"   - Agente inteligente\")\n",
       "        print(\"   - Tempo real\")\n",
       "        \n",
       "    def processar_entrada_futurista(self, entrada, tipo=\"texto\"):\n",
       "        \"\"\"Processa entrada usando todas as capacidades\"\"\"\n",
       "        print(f\"üîÆ Processando entrada {tipo}: {entrada[:50]}...\")\n",
       "        \n",
       "        # Aqui voc√™ implementaria o processamento completo\n",
       "        resposta = f\"Resposta futurista para: {entrada}\"\n",
       "        \n",
       "        return resposta\n",
       "\n",
       "# Criando e testando o sistema futurista\n",
       "sistema_futurista = SistemaRAGFuturista(llm)\n",
       "sistema_futurista.inicializar_sistema()\n",
       "\n",
       "print(\"\\nüß™ TESTANDO SISTEMA FUTURISTA\")\n",
       "print(\"=\" * 50)\n",
       "\n",
       "# Testando diferentes tipos de entrada\n",
       "entradas_teste = [\n",
       "    (\"O que √© RAG?\", \"texto\"),\n",
       "    (\"Analise esta imagem de um gato\", \"imagem\"),\n",
       "    (\"Calcule 15 + 27\", \"matematica\"),\n",
       "    (\"Qual a tend√™ncia atual de IA?\", \"tempo_real\")\n",
       "]\n",
       "\n",
       "for entrada, tipo in entradas_teste:\n",
       "    resposta = sistema_futurista.processar_entrada_futurista(entrada, tipo)\n",
       "    print(f\"\\nüîÆ {tipo.upper()}: {entrada}\")\n",
       "    print(f\"ü§ñ Resposta: {resposta}\")\n",
       "\n",
       "print(\"\\nüéâ Sistema RAG Futurista funcionando perfeitamente!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Na Pr√°tica, Meu Consagrado!** üí™\n",
       "\n",
       "**O que exploramos nos T√≥picos Avan√ßados:**\n",
       "\n",
       "1. ‚úÖ **RAG Multimodal** - Processando texto, imagens e mais\n",
       "2. ‚úÖ **Mem√≥ria Avan√ßada** - Conversas muito longas\n",
       "3. ‚úÖ **Agentes Inteligentes** - RAG que toma decis√µes\n",
       "4. ‚úÖ **Fine-tuning Personalizado** - RAG especializado\n",
       "5. ‚úÖ **RAG em Tempo Real** - Processamento cont√≠nuo\n",
       "6. ‚úÖ **Sistema Futurista** - Combinando tudo\n",
       "\n",
       "### **Vantagens dos T√≥picos Avan√ßados**\n",
       "\n",
       "- **Multimodalidade**: Processa diferentes tipos de dados\n",
       "- **Mem√≥ria Profunda**: Lembra de conversas muito longas\n",
       "- **Intelig√™ncia**: Pode tomar decis√µes e executar a√ß√µes\n",
       "- **Personaliza√ß√£o**: Adaptado para dom√≠nios espec√≠ficos\n",
       "- **Tempo Real**: Processa dados continuamente\n",
       "- **Escalabilidade**: Sistemas prontos para produ√ß√£o\n",
       "\n",
       "### **Tend√™ncias Futuras do RAG**\n",
       "\n",
       "**üîÆ O que vem por a√≠:**\n",
       "- **RAG Multimodal Avan√ßado**: V√≠deo, √°udio, 3D\n",
       "- **RAG Federado**: Dados distribu√≠dos e privados\n",
       "- **RAG Qu√¢ntico**: Computa√ß√£o qu√¢ntica para RAG\n",
       "- **RAG Biol√≥gico**: Inspirado em sistemas biol√≥gicos\n",
       "- **RAG Aut√¥nomo**: Sistemas que se auto-otimizam\n",
       "- **RAG Consciente**: Sistemas com autoconsci√™ncia\n",
       "\n",
       "### **Pr√≥ximos Passos**\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Linha do tempo mostrando a evolu√ß√£o do RAG\n",
       "\n",
       "**üéØ Voc√™ agora √© um especialista em RAG!**\n",
       "\n",
       "** Resumo do M√≥dulo 10**:\n",
       "- ‚úÖ Exploramos as fronteiras mais avan√ßadas do RAG\n",
       "- ‚úÖ Criamos sistemas multimodais e inteligentes\n",
       "- ‚úÖ Implementamos mem√≥ria avan√ßada e tempo real\n",
       "- ‚úÖ Desenvolvemos agentes que tomam decis√µes\n",
       "- ‚úÖ Constru√≠mos um sistema futurista completo\n",
       "\n",
       "**üöÄ Voc√™ est√° pronto para o futuro do RAG!**\n",
       "\n",
       "---\n",
       "\n",
       "** Dica do Pedro**: Os t√≥picos avan√ßados s√£o como explorar o espa√ßo - sempre h√° mais para descobrir! Continue experimentando e inovando!\n",
       "\n",
       "**üéâ PARAB√âNS! Voc√™ completou o curso completo de RAG!**\n",
       "\n",
       "**üèÜ Certificado de Especialista em RAG**\n",
       "\n",
       "Voc√™ agora domina:\n",
       "- ‚úÖ Fundamentos de RAG\n",
       "- ‚úÖ Embeddings e Vector Stores\n",
       "- ‚úÖ Document Loaders e Text Splitting\n",
       "- ‚úÖ Retrieval Avan√ßado\n",
       "- ‚úÖ Sistemas RAG Completos\n",
       "- ‚úÖ Projetos Pr√°ticos\n",
       "- ‚úÖ Deploy e Produ√ß√£o\n",
       "- ‚úÖ T√≥picos Avan√ßados\n",
       "\n",
       "**üöÄ Continue explorando e criando o futuro da IA!**"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 4
   }