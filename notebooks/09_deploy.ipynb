{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# ÔøΩÔøΩ **M√≥dulo 9: Deploy - Colocando os Projetos na Rua**\n",
       "\n",
       "> *Agora vamos levar nossos projetos RAG para o mundo real!*\n",
       "\n",
       "---\n",
       "\n",
       "## **Aula 9.1: O que √© Deploy e por que √© como Abrir uma Loja?**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas o que √© Deploy?**\n",
       "\n",
       "Deploy √© como **abrir uma loja** - voc√™ construiu tudo na \"oficina\" (desenvolvimento), agora precisa colocar na rua para que as pessoas possam usar! üè™\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Uma loja sendo inaugurada com clientes entrando\n",
       "\n",
       "**Por que Deploy √© importante?**\n",
       "\n",
       "√â como a diferen√ßa entre:\n",
       "- üè† **Projeto na garagem**: S√≥ voc√™ pode usar\n",
       "- **Loja na rua**: Todo mundo pode usar\n",
       "\n",
       "### **Analogia do Dia a Dia**\n",
       "\n",
       "Deploy √© como **lan√ßar um produto no mercado**:\n",
       "- üß™ **Laborat√≥rio**: Desenvolvimento e testes\n",
       "- ÔøΩÔøΩ **F√°brica**: Produ√ß√£o em escala\n",
       "- üõí **Loja**: Dispon√≠vel para o p√∫blico\n",
       "- üìà **Sucesso**: Clientes satisfeitos\n",
       "\n",
       "**Sem Deploy** seria como ter um produto incr√≠vel que ningu√©m pode usar! üòÖ\n",
       "\n",
       "---\n",
       "\n",
       "### **Setup Inicial - Preparando o Terreno**\n",
       "\n",
       "**‚ö†Ô∏è IMPORTANTE**: Se voc√™ n√£o executou o notebook `00_setup_colab.ipynb` primeiro, execute a c√©lula abaixo para instalar as depend√™ncias."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üöÄ SETUP GRATUITO PARA COLAB\n",
       "# Execute esta c√©lula primeiro para configurar o ambiente!\n",
       "\n",
       "# Instalando depend√™ncias para deploy\n",
       "!pip install langchain>=0.1.0\n",
       "!pip install langchain-community>=0.0.10\n",
       "!pip install langchain-core>=0.1.0\n",
       "!pip install python-dotenv>=1.0.0\n",
       "!pip install streamlit>=1.28.0\n",
       "!pip install gradio>=4.0.0\n",
       "!pip install fastapi>=0.104.0\n",
       "!pip install uvicorn>=0.24.0\n",
       "!pip install huggingface_hub>=0.19.0\n",
       "!pip install sentence-transformers>=2.2.0\n",
       "!pip install chromadb>=0.4.0\n",
       "\n",
       "print(\"‚úÖ Depend√™ncias de deploy instaladas com sucesso!\")\n",
       "print(\"üåê Pronto para colocar os projetos na rua!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üåê IMPORTA√á√ïES PARA DEPLOY\n",
       "import os\n",
       "import json\n",
       "from dotenv import load_dotenv\n",
       "\n",
       "# Frameworks de deploy\n",
       "import streamlit as st\n",
       "import gradio as gr\n",
       "from fastapi import FastAPI\n",
       "import uvicorn\n",
       "\n",
       "# LangChain\n",
       "from langchain_community.llms import HuggingFaceHub\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_community.vectorstores import Chroma\n",
       "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
       "from langchain.chains import ConversationalRetrievalChain\n",
       "from langchain.memory import ConversationBufferMemory\n",
       "from langchain.schema import Document\n",
       "\n",
       "print(\"‚úÖ Bibliotecas de deploy importadas com sucesso!\")\n",
       "print(\"üåê Pronto para criar interfaces web!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Exemplo Pr√°tico - Criando Nosso Primeiro Sistema RAG**\n",
       "\n",
       "Vamos criar um sistema RAG simples que vamos deployar. √â como preparar o produto antes de abrir a loja! üì¶"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ EXEMPLO PR√ÅTICO: CRIANDO NOSSO SISTEMA RAG PARA DEPLOY\n",
       "\n",
       "# Base de conhecimento simples para teste\n",
       "base_conhecimento = [\n",
       "    \"RAG (Retrieval Augmented Generation) √© uma t√©cnica que combina busca de informa√ß√µes com gera√ß√£o de texto.\",\n",
       "    \"LangChain √© um framework para construir aplica√ß√µes com LLMs de forma modular e eficiente.\",\n",
       "    \"Streamlit √© uma biblioteca Python para criar aplica√ß√µes web de forma simples e r√°pida.\",\n",
       "    \"Gradio √© uma biblioteca para criar interfaces de usu√°rio para modelos de machine learning.\",\n",
       "    \"FastAPI √© um framework web moderno para criar APIs com Python.\",\n",
       "    \"Deploy √© o processo de colocar uma aplica√ß√£o em produ√ß√£o para que usu√°rios possam acess√°-la.\",\n",
       "    \"Cloud computing permite executar aplica√ß√µes em servidores remotos sem gerenciar infraestrutura.\",\n",
       "    \"Docker √© uma plataforma para criar, distribuir e executar aplica√ß√µes em containers.\",\n",
       "    \"Kubernetes √© um sistema de orquestra√ß√£o de containers para aplica√ß√µes em escala.\",\n",
       "    \"CI/CD (Continuous Integration/Continuous Deployment) automatiza o processo de desenvolvimento e deploy.\"\n",
       "]\n",
       "\n",
       "# Criando documentos\n",
       "documentos = [Document(page_content=texto, metadata={\"fonte\": \"base_deploy\", \"id\": i}) \n",
       "              for i, texto in enumerate(base_conhecimento)]\n",
       "\n",
       "# Dividindo em peda√ßos\n",
       "text_splitter = RecursiveCharacterTextSplitter(\n",
       "    chunk_size=200,\n",
       "    chunk_overlap=50\n",
       ")\n",
       "textos_divididos = text_splitter.split_documents(documentos)\n",
       "\n",
       "print(f\"ÔøΩÔøΩ Sistema RAG criado com {len(textos_divididos)} documentos\")\n",
       "print(\"üåê Pronto para ser deployado!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üß† CONFIGURANDO O SISTEMA RAG\n",
       "\n",
       "# Configurando embeddings e vector store\n",
       "embeddings = HuggingFaceEmbeddings(\n",
       "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
       ")\n",
       "\n",
       "vectorstore = Chroma.from_documents(\n",
       "    documents=textos_divididos,\n",
       "    embedding=embeddings,\n",
       "    collection_name=\"base_deploy\"\n",
       ")\n",
       "\n",
       "# Configurando LLM\n",
       "def get_llm_colab():\n",
       "    \"\"\"Retorna o melhor LLM dispon√≠vel no Colab\"\"\"\n",
       "    try:\n",
       "        from langchain_openai import ChatOpenAI\n",
       "        api_key = os.getenv(\"OPENAI_API_KEY\")\n",
       "        if api_key:\n",
       "            return ChatOpenAI(\n",
       "                model=\"gpt-3.5-turbo\",\n",
       "                temperature=0.7,\n",
       "                api_key=api_key\n",
       "            )\n",
       "    except:\n",
       "        pass\n",
       "    \n",
       "    return HuggingFaceHub(\n",
       "        repo_id=\"google/flan-t5-base\",\n",
       "        model_kwargs={\"temperature\": 0.7, \"max_length\": 512}\n",
       "    )\n",
       "\n",
       "llm = get_llm_colab()\n",
       "\n",
       "# Criando sistema RAG\n",
       "memory = ConversationBufferMemory(\n",
       "    memory_key=\"chat_history\",\n",
       "    return_messages=True\n",
       ")\n",
       "\n",
       "rag_system = ConversationalRetrievalChain.from_llm(\n",
       "    llm=llm,\n",
       "    retriever=vectorstore.as_retriever(search_kwargs={\"k\": 3}),\n",
       "    memory=memory,\n",
       "    return_source_documents=True\n",
       ")\n",
       "\n",
       "print(\"ÔøΩÔøΩ Sistema RAG configurado!\")\n",
       "print(\"üåê Pronto para criar interfaces web!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 9.2: Deploy com Streamlit - Interface Web Simples**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas como criar uma interface web?**\n",
       "\n",
       "Vamos criar uma **interface web simples** com Streamlit. √â como criar a vitrine da nossa loja! üè™\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Uma vitrine de loja bem organizada e atrativa"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üè™ CRIANDO INTERFACE WEB COM STREAMLIT\n",
       "\n",
       "# Fun√ß√£o para criar a aplica√ß√£o Streamlit\n",
       "def criar_app_streamlit():\n",
       "    \"\"\"Cria uma aplica√ß√£o Streamlit para o sistema RAG\"\"\"\n",
       "    \n",
       "    # Configurando a p√°gina\n",
       "    st.set_page_config(\n",
       "        page_title=\"RAG Assistant\",\n",
       "        page_icon=\"ü§ñ\",\n",
       "        layout=\"wide\"\n",
       "    )\n",
       "    \n",
       "    # T√≠tulo da aplica√ß√£o\n",
       "    st.title(\"ÔøΩÔøΩ RAG Assistant - Seu Assistente Inteligente\")\n",
       "    st.markdown(\"---\")\n",
       "    \n",
       "    # Descri√ß√£o\n",
       "    st.markdown(\"\"\"\n",
       "    ### Como usar:\n",
       "    1. Digite sua pergunta na caixa abaixo\n",
       "    2. Clique em 'Perguntar'\n",
       "    3. Veja a resposta baseada em nossa base de conhecimento\n",
       "    \"\"\")\n",
       "    \n",
       "    # Inicializando chat history\n",
       "    if \"messages\" not in st.session_state:\n",
       "        st.session_state.messages = []\n",
       "    \n",
       "    # Mostrando hist√≥rico de mensagens\n",
       "    for message in st.session_state.messages:\n",
       "        with st.chat_message(message[\"role\"]):\n",
       "            st.markdown(message[\"content\"])\n",
       "    \n",
       "    # Input do usu√°rio\n",
       "    if prompt := st.chat_input(\"Digite sua pergunta aqui...\"):\n",
       "        # Adicionando mensagem do usu√°rio\n",
       "        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
       "        with st.chat_message(\"user\"):\n",
       "            st.markdown(prompt)\n",
       "        \n",
       "        # Gerando resposta\n",
       "        with st.chat_message(\"assistant\"):\n",
       "            with st.spinner(\"ü§î Pensando...\"):\n",
       "                try:\n",
       "                    resultado = rag_system({\"question\": prompt})\n",
       "                    resposta = resultado['answer']\n",
       "                    \n",
       "                    st.markdown(resposta)\n",
       "                    \n",
       "                    # Mostrando fontes\n",
       "                    if resultado['source_documents']:\n",
       "                        with st.expander(\"ÔøΩÔøΩ Ver fontes consultadas\"):\n",
       "                            for i, doc in enumerate(resultado['source_documents'], 1):\n",
       "                                st.markdown(f\"**Fonte {i}:** {doc.page_content[:200]}...\")\n",
       "                    \n",
       "                    # Adicionando resposta ao hist√≥rico\n",
       "                    st.session_state.messages.append({\"role\": \"assistant\", \"content\": resposta})\n",
       "                    \n",
       "                except Exception as e:\n",
       "                    st.error(f\"‚ùå Erro: {e}\")\n",
       "    \n",
       "    # Sidebar com informa√ß√µes\n",
       "    with st.sidebar:\n",
       "        st.header(\"‚ÑπÔ∏è Sobre\")\n",
       "        st.markdown(\"\"\"\n",
       "        Este √© um sistema RAG (Retrieval Augmented Generation) que:\n",
       "        \n",
       "        - üîç Busca informa√ß√µes relevantes\n",
       "        - üß† Gera respostas inteligentes\n",
       "        - üìö Usa uma base de conhecimento\n",
       "        - ÔøΩÔøΩ Mant√©m contexto da conversa\n",
       "        \n",
       "        **Tecnologias:**\n",
       "        - LangChain\n",
       "        - Hugging Face\n",
       "        - Streamlit\n",
       "        \"\"\")\n",
       "        \n",
       "        # Bot√£o para limpar hist√≥rico\n",
       "        if st.button(\"ÔøΩÔøΩÔ∏è Limpar Conversa\"):\n",
       "            st.session_state.messages = []\n",
       "            st.rerun()\n",
       "\n",
       "print(\"üè™ Aplica√ß√£o Streamlit criada!\")\n",
       "print(\"üåê Para executar: streamlit run app_streamlit.py\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üíæ SALVANDO A APLICA√á√ÉO STREAMLIT\n",
       "\n",
       "# Criando arquivo da aplica√ß√£o Streamlit\n",
       "app_streamlit_code = \"\"\"\n",
       "import streamlit as st\n",
       "import os\n",
       "from dotenv import load_dotenv\n",
       "from langchain_community.llms import HuggingFaceHub\n",
       "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
       "from langchain_community.vectorstores import Chroma\n",
       "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
       "from langchain.chains import ConversationalRetrievalChain\n",
       "from langchain.memory import ConversationBufferMemory\n",
       "from langchain.schema import Document\n",
       "\n",
       "# Configurando a p√°gina\n",
       "st.set_page_config(\n",
       "    page_title=\"RAG Assistant\",\n",
       "    page_icon=\"ü§ñ\",\n",
       "    layout=\"wide\"\n",
       ")\n",
       "\n",
       "# T√≠tulo da aplica√ß√£o\n",
       "st.title(\"ÔøΩÔøΩ RAG Assistant - Seu Assistente Inteligente\")\n",
       "st.markdown(\"---\")\n",
       "\n",
       "# Inicializando chat history\n",
       "if \"messages\" not in st.session_state:\n",
       "    st.session_state.messages = []\n",
       "\n",
       "# Mostrando hist√≥rico de mensagens\n",
       "for message in st.session_state.messages:\n",
       "    with st.chat_message(message[\"role\"]):\n",
       "        st.markdown(message[\"content\"])\n",
       "\n",
       "# Input do usu√°rio\n",
       "if prompt := st.chat_input(\"Digite sua pergunta aqui...\"):\n",
       "    # Adicionando mensagem do usu√°rio\n",
       "    st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n",
       "    with st.chat_message(\"user\"):\n",
       "        st.markdown(prompt)\n",
       "    \n",
       "    # Gerando resposta (simulada)\n",
       "    with st.chat_message(\"assistant\"):\n",
       "        with st.spinner(\"ü§î Pensando...\"):\n",
       "            resposta = f\"Resposta para: {prompt}\"\n",
       "            st.markdown(resposta)\n",
       "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": resposta})\n",
       "\n",
       "# Sidebar\n",
       "with st.sidebar:\n",
       "    st.header(\"‚ÑπÔ∏è Sobre\")\n",
       "    st.markdown(\"Sistema RAG com Streamlit\")\n",
       "    \n",
       "    if st.button(\"ÔøΩÔøΩÔ∏è Limpar Conversa\"):\n",
       "        st.session_state.messages = []\n",
       "        st.rerun()\n",
       "\"\"\"\n",
       "\n",
       "# Salvando arquivo\n",
       "with open('app_streamlit.py', 'w', encoding='utf-8') as file:\n",
       "    file.write(app_streamlit_code)\n",
       "\n",
       "print(\"üíæ Aplica√ß√£o Streamlit salva como 'app_streamlit.py'\")\n",
       "print(\"üöÄ Para executar: streamlit run app_streamlit.py\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 9.3: Deploy com Gradio - Interface R√°pida**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas e se eu quiser algo mais r√°pido?**\n",
       "\n",
       "Gradio √© como **abrir uma barraca r√°pida** - mais simples e direto ao ponto! üè™\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Uma barraca de comida r√°pida funcionando"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üè™ CRIANDO INTERFACE COM GRADIO\n",
       "\n",
       "# Fun√ß√£o para responder perguntas\n",
       "def responder_pergunta(pergunta, historico=\"\"):\n",
       "    \"\"\"Fun√ß√£o que responde perguntas usando o sistema RAG\"\"\"\n",
       "    try:\n",
       "        # Gerando resposta\n",
       "        resultado = rag_system({\"question\": pergunta})\n",
       "        resposta = resultado['answer']\n",
       "        \n",
       "        # Formatando resposta\n",
       "        resposta_formatada = f\"**Pergunta:** {pergunta}\\n\\n**Resposta:** {resposta}\"\n",
       "        \n",
       "        # Adicionando fontes se dispon√≠vel\n",
       "        if resultado['source_documents']:\n",
       "            resposta_formatada += \"\\n\\n**Fontes consultadas:**\\n\"\n",
       "            for i, doc in enumerate(resultado['source_documents'], 1):\n",
       "                resposta_formatada += f\"{i}. {doc.page_content[:100]}...\\n\"\n",
       "        \n",
       "        return resposta_formatada\n",
       "        \n",
       "    except Exception as e:\n",
       "        return f\"‚ùå Erro: {e}\"\n",
       "\n",
       "# Criando interface Gradio\n",
       "def criar_interface_gradio():\n",
       "    \"\"\"Cria uma interface Gradio para o sistema RAG\"\"\"\n",
       "    \n",
       "    # Configurando a interface\n",
       "    with gr.Blocks(\n",
       "        title=\"RAG Assistant\",\n",
       "        theme=gr.themes.Soft()\n",
       "    ) as interface:\n",
       "        \n",
       "        # T√≠tulo\n",
       "        gr.Markdown(\n",
       "            \"\"\"\n",
       "            # ÔøΩÔøΩ RAG Assistant\n",
       "            ### Seu Assistente Inteligente\n",
       "            \n",
       "            Fa√ßa perguntas sobre tecnologia e receba respostas baseadas em nossa base de conhecimento!\n",
       "            \"\"\"\n",
       "        )\n",
       "        \n",
       "        with gr.Row():\n",
       "            with gr.Column(scale=2):\n",
       "                # Input\n",
       "                pergunta_input = gr.Textbox(\n",
       "                    label=\"Digite sua pergunta:\",\n",
       "                    placeholder=\"Ex: O que √© RAG?\",\n",
       "                    lines=3\n",
       "                )\n",
       "                \n",
       "                # Bot√£o\n",
       "                botao_perguntar = gr.Button(\n",
       "                    \"ü§î Perguntar\",\n",
       "                    variant=\"primary\"\n",
       "                )\n",
       "            \n",
       "            with gr.Column(scale=3):\n",
       "                # Output\n",
       "                resposta_output = gr.Markdown(\n",
       "                    label=\"Resposta:\",\n",
       "                    value=\"Aguardando sua pergunta...\"\n",
       "                )\n",
       "        \n",
       "        # Exemplos\n",
       "        gr.Examples(\n",
       "            examples=[\n",
       "                \"O que √© RAG?\",\n",
       "                \"Como funciona o LangChain?\",\n",
       "                \"O que √© Streamlit?\",\n",
       "                \"Como fazer deploy de uma aplica√ß√£o?\"\n",
       "            ],\n",
       "            inputs=pergunta_input\n",
       "        )\n",
       "        \n",
       "        # Conectando fun√ß√£o\n",
       "        botao_perguntar.click(\n",
       "            fn=responder_pergunta,\n",
       "            inputs=pergunta_input,\n",
       "            outputs=resposta_output\n",
       "        )\n",
       "        \n",
       "        # Enter tamb√©m funciona\n",
       "        pergunta_input.submit(\n",
       "            fn=responder_pergunta,\n",
       "            inputs=pergunta_input,\n",
       "            outputs=resposta_output\n",
       "        )\n",
       "    \n",
       "    return interface\n",
       "\n",
       "print(\"üè™ Interface Gradio criada!\")\n",
       "print(\"üåê Para executar: gradio app_gradio.py\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üíæ SALVANDO A APLICA√á√ÉO GRADIO\n",
       "\n",
       "# Criando arquivo da aplica√ß√£o Gradio\n",
       "app_gradio_code = \"\"\"\n",
       "import gradio as gr\n",
       "\n",
       "def responder_pergunta(pergunta):\n",
       "    \"\"\"Fun√ß√£o que responde perguntas\"\"\"\n",
       "    return f\"Resposta para: {pergunta}\"\n",
       "\n",
       "# Criando interface\n",
       "with gr.Blocks(title=\"RAG Assistant\") as interface:\n",
       "    gr.Markdown(\"# ÔøΩÔøΩ RAG Assistant\")\n",
       "    \n",
       "    with gr.Row():\n",
       "        pergunta = gr.Textbox(label=\"Pergunta:\")\n",
       "        resposta = gr.Markdown(label=\"Resposta:\")\n",
       "    \n",
       "    botao = gr.Button(\"Perguntar\")\n",
       "    botao.click(fn=responder_pergunta, inputs=pergunta, outputs=resposta)\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    interface.launch()\n",
       "\"\"\"\n",
       "\n",
       "# Salvando arquivo\n",
       "with open('app_gradio.py', 'w', encoding='utf-8') as file:\n",
       "    file.write(app_gradio_code)\n",
       "\n",
       "print(\"üíæ Aplica√ß√£o Gradio salva como 'app_gradio.py'\")\n",
       "print(\"üöÄ Para executar: python app_gradio.py\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 9.4: Deploy com FastAPI - API Profissional**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas e se eu quiser uma API profissional?**\n",
       "\n",
       "FastAPI √© como **abrir uma franquia** - mais profissional e escal√°vel! üè¢\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Um pr√©dio corporativo moderno"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üè¢ CRIANDO API COM FASTAPI\n",
       "\n",
       "# Criando aplica√ß√£o FastAPI\n",
       "app = FastAPI(\n",
       "    title=\"RAG Assistant API\",\n",
       "    description=\"API para sistema RAG inteligente\",\n",
       "    version=\"1.0.0\"\n",
       ")\n",
       "\n",
       "# Modelos de dados\n",
       "from pydantic import BaseModel\n",
       "from typing import List, Optional\n",
       "\n",
       "class PerguntaRequest(BaseModel):\n",
       "    pergunta: str\n",
       "    historico: Optional[List[str]] = []\n",
       "\n",
       "class RespostaResponse(BaseModel):\n",
       "    resposta: str\n",
       "    fontes: List[str]\n",
       "    tempo_processamento: float\n",
       "    status: str\n",
       "\n",
       "# Endpoints da API\n",
       "@app.get(\"/\")\n",
       "async def root():\n",
       "    return {\n",
       "        \"message\": \"RAG Assistant API\",\n",
       "        \"version\": \"1.0.0\",\n",
       "        \"status\": \"online\"\n",
       "    }\n",
       "\n",
       "@app.get(\"/health\")\n",
       "async def health_check():\n",
       "    return {\"status\": \"healthy\"}\n",
       "\n",
       "@app.post(\"/perguntar\", response_model=RespostaResponse)\n",
       "async def perguntar(request: PerguntaRequest):\n",
       "    \"\"\"Endpoint para fazer perguntas ao sistema RAG\"\"\"\n",
       "    import time\n",
       "    \n",
       "    inicio = time.time()\n",
       "    \n",
       "    try:\n",
       "        # Gerando resposta\n",
       "        resultado = rag_system({\"question\": request.pergunta})\n",
       "        resposta = resultado['answer']\n",
       "        \n",
       "        # Extraindo fontes\n",
       "        fontes = [doc.page_content[:100] + \"...\" for doc in resultado['source_documents']]\n",
       "        \n",
       "        tempo_processamento = time.time() - inicio\n",
       "        \n",
       "        return RespostaResponse(\n",
       "            resposta=resposta,\n",
       "            fontes=fontes,\n",
       "            tempo_processamento=tempo_processamento,\n",
       "            status=\"success\"\n",
       "        )\n",
       "        \n",
       "    except Exception as e:\n",
       "        tempo_processamento = time.time() - inicio\n",
       "        return RespostaResponse(\n",
       "            resposta=f\"Erro: {e}\",\n",
       "            fontes=[],\n",
       "            tempo_processamento=tempo_processamento,\n",
       "            status=\"error\"\n",
       "        )\n",
       "\n",
       "print(\"ÔøΩÔøΩ API FastAPI criada!\")\n",
       "print(\"üåê Para executar: uvicorn app_fastapi:app --reload\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üíæ SALVANDO A API FASTAPI\n",
       "\n",
       "# Criando arquivo da API\n",
       "app_fastapi_code = \"\"\"\n",
       "from fastapi import FastAPI\n",
       "from pydantic import BaseModel\n",
       "from typing import List, Optional\n",
       "import time\n",
       "\n",
       "app = FastAPI(title=\"RAG Assistant API\")\n",
       "\n",
       "class PerguntaRequest(BaseModel):\n",
       "    pergunta: str\n",
       "\n",
       "class RespostaResponse(BaseModel):\n",
       "    resposta: str\n",
       "    status: str\n",
       "\n",
       "@app.get(\"/\")\n",
       "async def root():\n",
       "    return {\"message\": \"RAG Assistant API\"}\n",
       "\n",
       "@app.post(\"/perguntar\")\n",
       "async def perguntar(request: PerguntaRequest):\n",
       "    return RespostaResponse(\n",
       "        resposta=f\"Resposta para: {request.pergunta}\",\n",
       "        status=\"success\"\n",
       "    )\n",
       "\n",
       "if __name__ == \"__main__\":\n",
       "    import uvicorn\n",
       "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
       "\"\"\"\n",
       "\n",
       "# Salvando arquivo\n",
       "with open('app_fastapi.py', 'w', encoding='utf-8') as file:\n",
       "    file.write(app_fastapi_code)\n",
       "\n",
       "print(\"üíæ API FastAPI salva como 'app_fastapi.py'\")\n",
       "print(\"üöÄ Para executar: uvicorn app_fastapi:app --reload\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## **Aula 9.5: Deploy na Nuvem - Colocando na Internet**\n",
       "\n",
       "---\n",
       "\n",
       "### **T√°, mas como colocar na internet?**\n",
       "\n",
       "Agora vamos aprender como **colocar nossos projetos na nuvem**. √â como abrir uma loja online! üåê\n",
       "\n",
       "**üñºÔ∏è Sugest√£o de imagem**: Servidores na nuvem com aplica√ß√µes rodando"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üåê CRIANDO ARQUIVOS PARA DEPLOY NA NUVEM\n",
       "\n",
       "# Requirements.txt para depend√™ncias\n",
       "requirements_content = \"\"\"\n",
       "langchain>=0.1.0\n",
       "langchain-community>=0.0.10\n",
       "langchain-core>=0.1.0\n",
       "python-dotenv>=1.0.0\n",
       "streamlit>=1.28.0\n",
       "gradio>=4.0.0\n",
       "fastapi>=0.104.0\n",
       "uvicorn>=0.24.0\n",
       "huggingface_hub>=0.19.0\n",
       "sentence-transformers>=2.2.0\n",
       "chromadb>=0.4.0\n",
       "pydantic>=2.0.0\n",
       "\"\"\"\n",
       "\n",
       "with open('requirements.txt', 'w') as file:\n",
       "    file.write(requirements_content)\n",
       "\n",
       "print(\"üì¶ requirements.txt criado!\")\n",
       "print(\"üåê Lista de depend√™ncias pronta para deploy!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CRIANDO DOCKERFILE PARA CONTAINERIZA√á√ÉO\n",
       "\n",
       "dockerfile_content = \"\"\"\n",
       "# Usando imagem Python oficial\n",
       "FROM python:3.9-slim\n",
       "\n",
       "# Definindo diret√≥rio de trabalho\n",
       "WORKDIR /app\n",
       "\n",
       "# Copiando requirements\n",
       "COPY requirements.txt .\n",
       "\n",
       "# Instalando depend√™ncias\n",
       "RUN pip install --no-cache-dir -r requirements.txt\n",
       "\n",
       "# Copiando c√≥digo da aplica√ß√£o\n",
       "COPY . .\n",
       "\n",
       "# Expondo porta\n",
       "EXPOSE 8501\n",
       "\n",
       "# Comando para executar\n",
       "CMD [\"streamlit\", \"run\", \"app_streamlit.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\"]\n",
       "\"\"\"\n",
       "\n",
       "with open('Dockerfile', 'w') as file:\n",
       "    file.write(dockerfile_content)\n",
       "\n",
       "print(\"ÔøΩÔøΩ Dockerfile criado!\")\n",
       "print(\"üåê Container pronto para deploy!\")"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# ÔøΩÔøΩ CRIANDO ARQUIVO DE CONFIGURA√á√ÉO PARA STREAMLIT CLOUD\n",
       "\n",
       "# .streamlit/config.toml\n",
       "config_content = \"\"\"\n",
       "[server]\n",
       "port = 8501\n",
       "address = \"0.0.0.0\"\n",
       "\n",
       "[browser]\n",
       "gatherUsageStats = false\n",
       "\n",
       "[theme]\n",
       "primaryColor = \"#FF6B6B\"\n",
       "backgroundColor = \"#FFFFFF\"\n",
       "secondaryBackgroundColor = \"#F0F2F6\"\n",
       "textColor = \"#262730\"\n",
       "\"\"\"\n",
       "\n",
       "# Criando diret√≥rio .streamlit\n",
       "import os\n",
       "os.makedirs('.streamlit', exist_ok=True)\n",
       "\n",
       "with open('.streamlit/config.toml', 'w') as file:\n",
       "    file.write(config_content)\n",
       "\n",
       "print(\"üìã Configura√ß√£o Streamlit criada!\")\n",
       "print(\"ÔøΩÔøΩ Pronto para deploy no Streamlit Cloud!\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### **Desafio do M√≥dulo - Criando um Sistema de Deploy Automatizado**\n",
       "\n",
       "Vamos criar um sistema que automatiza o processo de deploy:"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "# üéØ DESAFIO: SISTEMA DE DEPLOY AUTOMATIZADO\n",
       "\n",
       "class SistemaDeploy:\n",
       "    \"\"\"Sistema automatizado para deploy de aplica√ß√µes RAG\"\"\"\n",
       "    \n",
       "    def __init__(self):\n",
       "        self.plataformas = {\n",
       "            \"streamlit\": \"Streamlit Cloud\",\n",
       "            \"gradio\": \"Hugging Face Spaces\",\n",
       "            \"fastapi\": \"Railway/Render\",\n",
       "            \"docker\": \"Docker Hub\"\n",
       "        }\n",
       "    \n",
       "    def criar_deploy_streamlit(self, nome_app):\n",
       "        \"\"\"Cria deploy para Streamlit Cloud\"\"\"\n",
       "        print(f\"üöÄ Criando deploy para {nome_app} no Streamlit Cloud...\")\n",
       "        \n",
       "        # Instru√ß√µes de deploy\n",
       "        instrucoes = f\"\"\"\n",
       "        üìã INSTRU√á√ïES PARA DEPLOY NO STREAMLIT CLOUD:\n",
       "        \n",
       "        1. Acesse: https://share.streamlit.io/\n",
       "        2. Fa√ßa login com GitHub\n",
       "        3. Clique em 'New app'\n",
       "        4. Selecione seu reposit√≥rio\n",
       "        5. Defina o arquivo principal: {nome_app}.py\n",
       "        6. Clique em 'Deploy!'\n",
       "        \n",
       "        ‚úÖ Seu app estar√° dispon√≠vel em: https://{nome_app}-seu-usuario.streamlit.app\n",
       "        \"\"\"\n",
       "        \n",
       "        return instrucoes\n",
       "    \n",
       "    def criar_deploy_gradio(self, nome_app):\n",
       "        \"\"\"Cria deploy para Hugging Face Spaces\"\"\"\n",
       "        print(f\"üöÄ Criando deploy para {nome_app} no Hugging Face Spaces...\")\n",
       "        \n",
       "        instrucoes = f\"\"\"\n",
       "        üìã INSTRU√á√ïES PARA DEPLOY NO HUGGING FACE SPACES:\n",
       "        \n",
       "        1. Acesse: https://huggingface.co/spaces\n",
       "        2. Clique em 'Create new Space'\n",
       "        3. Escolha 'Gradio' como SDK\n",
       "        4. Fa√ßa upload dos arquivos\n",
       "        5. Aguarde o build autom√°tico\n",
       "        \n",
       "        ‚úÖ Seu app estar√° dispon√≠vel em: https://huggingface.co/spaces/seu-usuario/{nome_app}\n",
       "        \"\"\"\n",
       "        \n",
       "        return instrucoes\n",
       "    \n",
       "    def criar_deploy_fastapi(self, nome_app):\n",
       "        \"\"\"Cria deploy para Railway/Render\"\"\"\n",
       "        print(f\"üöÄ Criando deploy para {nome_app} no Railway/Render...\")\n",
       "        \n",
       "        instrucoes = f\"\"\"\n",
       "        üìã INSTRU√á√ïES PARA DEPLOY NO RAILWAY:\n",
       "        \n",
       "        1. Acesse: https://railway.app/\n",
       "        2. Conecte seu GitHub\n",
       "        3. Clique em 'New Project'\n",
       "        4. Selecione 'Deploy from GitHub repo'\n",
       "        5. Configure as vari√°veis de ambiente\n",
       "        6. Deploy autom√°tico!\n",
       "        \n",
       "        ‚úÖ Seu app estar√° dispon√≠vel em: https://{nome_app}-seu-projeto.railway.app\n",
       "        \"\"\"\n",
       "        \n",
       "        return instrucoes\n",
       "\n",
       "# Testando o sistema de deploy\n",
       "sistema_deploy = SistemaDeploy()\n",
       "\n",
       "print(\"üéØ TESTANDO SISTEMA DE DEPLOY AUTOMATIZADO\")\n",
       "print(\"=\" * 60)\n",
       "\n",
       "# Deploy Streamlit\n",
       "print(\"\\nÔøΩÔøΩ Deploy Streamlit:\")\n",
       "print(sistema_deploy.criar_deploy_streamlit(\"rag-assistant\"))\n",
       "\n",
       "print(\"\\n\" + \"-\" * 40)\n",
       "\n",
       "# Deploy Gradio\n",
       "print(\"\\nÔøΩÔøΩ Deploy Gradio:\")\n",
       "print(sistema_deploy.criar_deploy_gradio(\"rag-assistant\"))\n",
       "\n",
        "print(\"\\n\" + \"-\" * 40)\n",
        "\n",
        "# Deploy FastAPI\n",
        "print(\"\\nüè¢ Deploy FastAPI:\")\n",
        "print(sistema_deploy.criar_deploy_fastapi(\"rag-assistant\"))\n",
        "\n",
        "print(\"\\nüéâ Sistema de deploy funcionando perfeitamente!\")"
    ]
    },
    {
    "cell_type": "markdown",
    "metadata": {},
    "source": [
        "### **Na Pr√°tica, Meu Consagrado!** üí™\n",
        "\n",
        "**O que aprendemos sobre Deploy:**\n",
        "\n",
        "1. ‚úÖ **Streamlit** - Interface web simples e r√°pida\n",
        "2. ‚úÖ **Gradio** - Interface ainda mais simples\n",
        "3. ‚úÖ **FastAPI** - API profissional e escal√°vel\n",
        "4. ‚úÖ **Deploy na Nuvem** - Colocando na internet\n",
        "5. ‚úÖ **Automa√ß√£o** - Sistema de deploy automatizado\n",
        "\n",
        "### **Vantagens do Deploy**\n",
        "\n",
        "- **Acessibilidade**: Qualquer pessoa pode usar sua aplica√ß√£o\n",
        "- **Escalabilidade**: Pode atender milhares de usu√°rios\n",
        "- **Disponibilidade**: Funciona 24/7 sem interrup√ß√£o\n",
        "- **Profissionalismo**: Aplica√ß√µes prontas para produ√ß√£o\n",
        "- **Colabora√ß√£o**: Equipes podem trabalhar juntas\n",
        "- **Feedback**: Usu√°rios reais testando suas aplica√ß√µes\n",
        "\n",
        "### **Plataformas de Deploy Gratuitas**\n",
        "\n",
        "**üÜì Op√ß√µes gratuitas para come√ßar:**\n",
        "- **Streamlit Cloud**: Perfeito para aplica√ß√µes Streamlit\n",
        "- **Hugging Face Spaces**: Ideal para Gradio e modelos de IA\n",
        "- **Railway**: √ìtimo para APIs e aplica√ß√µes complexas\n",
        "- **Render**: Alternativa gratuita para v√°rios tipos de apps\n",
        "- **Heroku**: Plataforma cl√°ssica (com limita√ß√µes gratuitas)\n",
        "\n",
        "### **Pr√≥ximos Passos**\n",
        "\n",
        "**üñºÔ∏è Sugest√£o de imagem**: Fluxo completo de desenvolvimento at√© deploy\n",
        "\n",
        "**üéØ Pr√≥ximo m√≥dulo**: Vamos explorar **T√≥picos Avan√ßados** - o que vem depois!\n",
        "\n",
        "** Resumo do M√≥dulo 9**:\n",
        "- ‚úÖ Criamos interfaces web com Streamlit e Gradio\n",
        "- ‚úÖ Desenvolvemos APIs profissionais com FastAPI\n",
        "- ‚úÖ Aprendemos a fazer deploy na nuvem\n",
        "- ‚úÖ Automatizamos o processo de deploy\n",
        "- ‚úÖ Conhecemos plataformas gratuitas\n",
        "\n",
        "**üöÄ Agora voc√™ pode colocar seus projetos RAG na rua!**\n",
        "\n",
        "---\n",
        "\n",
        "**ÔøΩÔøΩ Dica do Pedro**: O deploy √© como abrir uma loja - primeiro voc√™ testa na garagem, depois coloca na rua. Comece com plataformas gratuitas e evolua conforme necess√°rio!\n",
        "\n",
        "**üöÄ Pr√≥ximo m√≥dulo**: T√≥picos Avan√ßados - Explorando o futuro do RAG! üîÆ"
    ]
    }
    ],
    "metadata": {
    "kernelspec": {
    "display_name": "Python 3",
    "language": "python",
    "name": "python3"
    },
    "language_info": {
    "codemirror_mode": {
        "name": "ipython",
        "version": 3
    },
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": "3.8.5"
    }
    },
    "nbformat": 4,
    "nbformat_minor": 4
    }